{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input trajectory shape: (8, 6)\n",
      "Number of environmental timesteps: 8\n",
      "\n",
      "One environmental data point contains:\n",
      "  wind fields: ['u_300', 'v_300', 'u_500', 'v_500', 'u_700', 'v_700', 'u_850', 'v_850']\n",
      "    u_300 shape: (21, 21)\n",
      "  sst shape: (21, 21)\n",
      "  geopotential shape: (21, 41)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load one of your processed samples\n",
    "with open('Processed_Data_Subset/processed_samples_1980.pkl', 'rb') as f:\n",
    "    samples = pickle.load(f)\n",
    "\n",
    "sample = samples[0]  # Look at first sample\n",
    "\n",
    "print(\"Input trajectory shape:\", sample['input_trajectory'].shape)\n",
    "print(\"Number of environmental timesteps:\", len(sample['environmental_data']))\n",
    "print(\"\\nOne environmental data point contains:\")\n",
    "for key in sample['environmental_data'][0].keys():\n",
    "    if key == 'wind':\n",
    "        print(f\"  wind fields: {list(sample['environmental_data'][0]['wind'].keys())}\")\n",
    "        print(f\"    u_300 shape: {sample['environmental_data'][0]['wind']['u_300'].shape}\")\n",
    "    elif key == 'sst':\n",
    "        print(f\"  sst shape: {sample['environmental_data'][0]['sst'].shape}\")\n",
    "    elif key == 'geopotential':\n",
    "        print(f\"  geopotential shape: {sample['environmental_data'][0]['geopotential'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding (Same as vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "class SinusoidalPositionEmbedding(nn.Module):\n",
    "    \"\"\"Timestep embedding for diffusion process.\"\"\"\n",
    "    \n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, t):\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = t[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Diffusion with DDIM (Implicit Modeling) for faster convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusion:\n",
    "    \"\"\"\n",
    "    Simplified DDPM for storm track forecasting.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, timesteps=1000, beta_start=0.0001, beta_end=0.02):\n",
    "        self.timesteps = timesteps\n",
    "        \n",
    "        # Linear beta schedule\n",
    "        self.betas = torch.linspace(beta_start, beta_end, timesteps)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "        \n",
    "        # Calculations for diffusion q(x_t | x_{t-1})\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
    "        \n",
    "        # Calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        self.posterior_variance = (\n",
    "            self.betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "    \n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        \"\"\"\n",
    "        Forward diffusion: add noise to clean data.\n",
    "        \n",
    "        Args:\n",
    "            x_start: (batch, 5, 2) - clean future positions\n",
    "            t: (batch,) - diffusion timestep\n",
    "            noise: optional noise to add\n",
    "        \n",
    "        Returns:\n",
    "            x_t: noisy version of x_start at timestep t\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "        \n",
    "        sqrt_alpha = self.sqrt_alphas_cumprod[t]\n",
    "        sqrt_one_minus_alpha = self.sqrt_one_minus_alphas_cumprod[t]\n",
    "        \n",
    "        # Reshape for broadcasting\n",
    "        sqrt_alpha = sqrt_alpha[:, None, None]\n",
    "        sqrt_one_minus_alpha = sqrt_one_minus_alpha[:, None, None]\n",
    "        \n",
    "        return sqrt_alpha * x_start + sqrt_one_minus_alpha * noise\n",
    "    \n",
    "    def p_sample(self, model, x_t, t, past_traj, era5_features):\n",
    "        \"\"\"\n",
    "        Reverse diffusion: denoise one step.\n",
    "        \n",
    "        Args:\n",
    "            model: DiffusionTransformer\n",
    "            x_t: (batch, 5, 2) - noisy positions at timestep t\n",
    "            t: (batch,) - current timestep\n",
    "            past_traj: (batch, 8, 6) - conditioning\n",
    "            era5_features: (batch, 8, 10) - conditioning\n",
    "        \n",
    "        Returns:\n",
    "            x_{t-1}: less noisy positions\n",
    "        \"\"\"\n",
    "        # Predict noise\n",
    "        predicted_noise = model(past_traj, era5_features, x_t, t)\n",
    "        device = x_t.device\n",
    "\n",
    "        # Calculate x_0 prediction\n",
    "        alpha = self.alphas_cumprod.to(device)[t][:, None, None]\n",
    "        alpha_prev = self.alphas_cumprod_prev.to(device)[t][:, None, None]\n",
    "        beta = self.betas.to(device)[t][:, None, None]\n",
    "        \n",
    "        # Predict x_0\n",
    "        pred_x0 = (x_t - torch.sqrt(1 - alpha) * predicted_noise) / torch.sqrt(alpha)\n",
    "        \n",
    "        # Calculate x_{t-1}\n",
    "        alphas_t = self.alphas.to(device)[t][:, None, None]\n",
    "        mean = (\n",
    "            torch.sqrt(alpha_prev) * beta * pred_x0 +\n",
    "            torch.sqrt(alphas_t) * (1 - alpha_prev) * x_t\n",
    "        ) / (1 - alpha)\n",
    "        \n",
    "        if t[0] > 0:\n",
    "            noise = torch.randn_like(x_t)\n",
    "            variance = self.posterior_variance.to(device)[t][:, None, None]\n",
    "            return mean + torch.sqrt(variance) * noise\n",
    "        else:\n",
    "            return mean\n",
    "    \n",
    "    # @torch.no_grad()\n",
    "    # def sample(self, model, past_traj, era5_features, device):\n",
    "    #     \"\"\"\n",
    "    #     Generate storm track by denoising from pure noise.\n",
    "        \n",
    "    #     Args:\n",
    "    #         model: trained DiffusionTransformer\n",
    "    #         past_traj: (batch, 8, 6)\n",
    "    #         era5_features: (batch, 8, 10)\n",
    "        \n",
    "    #     Returns:\n",
    "    #         predicted_track: (batch, 5, 2) - forecasted positions\n",
    "    #     \"\"\"\n",
    "    #     batch_size = past_traj.shape[0]\n",
    "        \n",
    "    #     # Start from pure noise\n",
    "    #     x = torch.randn(batch_size, 5, 2, device=device)\n",
    "        \n",
    "    #     # Iteratively denoise\n",
    "    #     for i in reversed(range(self.timesteps)):\n",
    "    #         t = torch.full((batch_size,), i, device=device, dtype=torch.long)\n",
    "    #         x = self.p_sample(model, x, t, past_traj, era5_features)\n",
    "        \n",
    "    #     return x\n",
    "\n",
    "    # @torch.no_grad()\n",
    "    # def ddim_sample(self, model, past_traj, era5_features, device, steps=50):\n",
    "    #     \"\"\"\n",
    "    #     Fast sampling using DDIM with fewer steps.\n",
    "        \n",
    "    #     Args:\n",
    "    #         steps: Number of sampling steps (default 50, vs 1000 for DDPM)\n",
    "    #     \"\"\"\n",
    "    #     batch_size = past_traj.shape[0]\n",
    "        \n",
    "    #     # Select subset of timesteps to use\n",
    "    #     step_size = self.timesteps // steps\n",
    "    #     timesteps = list(range(0, self.timesteps, step_size))\n",
    "    #     timesteps = list(reversed(timesteps))\n",
    "        \n",
    "    #     # Start from pure noise\n",
    "    #     x = torch.randn(batch_size, 5, 2, device=device)\n",
    "        \n",
    "    #     # Iteratively denoise (only 'steps' iterations instead of 1000!)\n",
    "    #     for i, t_curr in enumerate(timesteps):\n",
    "    #         t = torch.full((batch_size,), t_curr, device=device, dtype=torch.long)\n",
    "            \n",
    "    #         # Predict noise\n",
    "    #         predicted_noise = model(past_traj, era5_features, x, t)\n",
    "            \n",
    "    #         # DDIM update (deterministic, no random noise added)\n",
    "    #         alpha = self.alphas_cumprod.to(device)[t][:, None, None]\n",
    "            \n",
    "    #         # Predict x_0\n",
    "    #         pred_x0 = (x - torch.sqrt(1 - alpha) * predicted_noise) / torch.sqrt(alpha)\n",
    "            \n",
    "    #         # Get next timestep\n",
    "    #         if i < len(timesteps) - 1:\n",
    "    #             t_next = timesteps[i + 1]\n",
    "    #             alpha_next = self.alphas_cumprod.to(device)[t_next][:, None, None]\n",
    "                \n",
    "    #             # DDIM step\n",
    "    #             x = torch.sqrt(alpha_next) * pred_x0 + torch.sqrt(1 - alpha_next) * predicted_noise\n",
    "    #         else:\n",
    "    #             x = pred_x0\n",
    "        \n",
    "    #     return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def ddim_sample(self, model, past_traj, era5_features, device, steps=50):\n",
    "        \"\"\"\n",
    "        Fast sampling using DDIM with fewer steps.\n",
    "        \n",
    "        Args:\n",
    "            steps: Number of sampling steps (default 50, vs 1000 for DDPM)\n",
    "        \"\"\"\n",
    "        batch_size = past_traj.shape[0]\n",
    "        \n",
    "        # Select subset of timesteps to use\n",
    "        step_size = self.timesteps // steps\n",
    "        timesteps = list(range(0, self.timesteps, step_size))\n",
    "        timesteps = list(reversed(timesteps))\n",
    "        \n",
    "        # Start from pure noise\n",
    "        x = torch.randn(batch_size, 5, 2, device=device)\n",
    "        \n",
    "        # Iteratively denoise (only 'steps' iterations instead of 1000!)\n",
    "        for i, t_curr in enumerate(timesteps):\n",
    "            t = torch.full((batch_size,), t_curr, device=device, dtype=torch.long)\n",
    "            \n",
    "            # Predict noise\n",
    "            predicted_noise = model(past_traj, era5_features, x, t)\n",
    "            \n",
    "            # DDIM update (deterministic, no random noise added)\n",
    "            alpha = self.alphas_cumprod.to(device)[t_curr]  # Scalar indexing\n",
    "            \n",
    "            # Predict x_0\n",
    "            pred_x0 = (x - torch.sqrt(1 - alpha) * predicted_noise) / torch.sqrt(alpha)\n",
    "            \n",
    "            # Get next timestep\n",
    "            if i < len(timesteps) - 1:\n",
    "                t_next = timesteps[i + 1]\n",
    "                alpha_next = self.alphas_cumprod.to(device)[t_next]  # Scalar indexing\n",
    "                \n",
    "                # DDIM step\n",
    "                x = torch.sqrt(alpha_next) * pred_x0 + torch.sqrt(1 - alpha_next) * predicted_noise\n",
    "            else:\n",
    "                x = pred_x0\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Based ERA5 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNN Encoder for ERA5 Spatial Fields\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ERA5CNNEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encode ERA5 spatial grids using CNN.\n",
    "    \n",
    "    Takes multiple 2D fields and produces a fixed-size embedding vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Separate encoders for different field types (different spatial sizes)\n",
    "        \n",
    "        # Wind + SST encoder (21x21 grids)\n",
    "        # Input: 9 channels (8 wind + 1 SST)\n",
    "        self.wind_sst_encoder = nn.Sequential(\n",
    "            nn.Conv2d(9, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 21x21 -> 10x10\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 10x10 -> 5x5\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),  # 5x5 -> 1x1\n",
    "        )\n",
    "        \n",
    "        # Geopotential encoder (21x41 grids)\n",
    "        # Input: 1 channel\n",
    "        self.geo_encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 21x41 -> 10x20\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 10x20 -> 5x10\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),  # 5x10 -> 1x1\n",
    "        )\n",
    "        \n",
    "        # Combine features and project to output dimension\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(128 + 64, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, env_data_batch):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            env_data_batch: List of environmental data (batch_size samples)\n",
    "            Each sample contains 8 timesteps of ERA5 fields\n",
    "        \n",
    "        Returns:\n",
    "            Tensor of shape (batch_size, n_timesteps, output_dim)\n",
    "        \"\"\"\n",
    "        device = next(self.wind_sst_encoder.parameters()).device\n",
    "        batch_features = []\n",
    "        \n",
    "        for env_timesteps in env_data_batch:  # Each sample in batch\n",
    "            timestep_features = []\n",
    "            \n",
    "            for env in env_timesteps:  # Each of 8 timesteps\n",
    "                # Prepare wind + SST (9 channels, 21x21)\n",
    "                wind_sst_fields = []\n",
    "                for level in [300, 500, 700, 850]:\n",
    "                    wind_sst_fields.append(env['wind'][f'u_{level}'])\n",
    "                    wind_sst_fields.append(env['wind'][f'v_{level}'])\n",
    "                wind_sst_fields.append(env['sst'])\n",
    "                \n",
    "                wind_sst = np.stack(wind_sst_fields, axis=0)  # (9, 21, 21)\n",
    "                \n",
    "                # Handle NaN values (replace with mean)\n",
    "                for i in range(wind_sst.shape[0]):\n",
    "                    field = wind_sst[i]\n",
    "                    if np.any(np.isnan(field)):\n",
    "                        wind_sst[i] = np.nan_to_num(field, nan=np.nanmean(field))\n",
    "                \n",
    "                wind_sst = torch.FloatTensor(wind_sst).unsqueeze(0).to(device)  # (1, 9, 21, 21)\n",
    "                \n",
    "                # Prepare geopotential (1 channel, 21x41)\n",
    "                geo = env['geopotential']\n",
    "                if np.any(np.isnan(geo)):\n",
    "                    geo = np.nan_to_num(geo, nan=np.nanmean(geo))\n",
    "                geo = torch.FloatTensor(geo).unsqueeze(0).unsqueeze(0).to(device)  # (1, 1, 21, 41)\n",
    "                \n",
    "                # Encode\n",
    "                wind_sst_feat = self.wind_sst_encoder(wind_sst).squeeze(-1).squeeze(-1)  # (1, 128)\n",
    "                geo_feat = self.geo_encoder(geo).squeeze(-1).squeeze(-1)  # (1, 64)\n",
    "                \n",
    "                # Fuse\n",
    "                combined = torch.cat([wind_sst_feat, geo_feat], dim=1)  # (1, 192)\n",
    "                fused = self.fusion(combined)  # (1, output_dim)\n",
    "                \n",
    "                timestep_features.append(fused)\n",
    "            \n",
    "            # Stack timesteps\n",
    "            timestep_features = torch.cat(timestep_features, dim=0)  # (8, output_dim)\n",
    "            batch_features.append(timestep_features)\n",
    "        \n",
    "        return torch.stack(batch_features, dim=0)  # (batch, 8, output_dim)\n",
    "\n",
    "\n",
    "class DiffusionTransformerCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Updated Diffusion Transformer using CNN encoder for ERA5.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model=256,\n",
    "        n_heads=8,\n",
    "        n_layers=6,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # CNN encoder for ERA5\n",
    "        self.era5_encoder = ERA5CNNEncoder(output_dim=d_model)\n",
    "        \n",
    "        # Embeddings\n",
    "        self.traj_embed = nn.Linear(6, d_model)\n",
    "        self.pos_embed = nn.Linear(2, d_model)\n",
    "        \n",
    "        # Diffusion timestep embedding\n",
    "        self.time_embed = nn.Sequential(\n",
    "            SinusoidalPositionEmbedding(d_model),\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model * 4, d_model)\n",
    "        )\n",
    "        \n",
    "        # Transformer encoder for conditioning\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.condition_encoder = nn.TransformerEncoder(encoder_layer, n_layers)\n",
    "        \n",
    "        # Transformer decoder for denoising\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.denoiser = nn.TransformerDecoder(decoder_layer, n_layers)\n",
    "        \n",
    "        # Output head\n",
    "        self.output_head = nn.Linear(d_model, 2)\n",
    "        \n",
    "        # Learnable positional encoding\n",
    "        self.forecast_pos_embed = nn.Parameter(torch.randn(5, d_model))\n",
    "    \n",
    "    def forward(self, past_traj, env_data_batch, noisy_positions, diffusion_t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            past_traj: (batch, 8, 6)\n",
    "            env_data_batch: List of environmental data dicts\n",
    "            noisy_positions: (batch, 5, 2)\n",
    "            diffusion_t: (batch,)\n",
    "        \"\"\"\n",
    "        batch_size = past_traj.shape[0]\n",
    "        \n",
    "        # Encode ERA5 with CNN\n",
    "        era5_tokens = self.era5_encoder(env_data_batch)  # (batch, 8, d_model)\n",
    "        \n",
    "        # Embed trajectory\n",
    "        traj_tokens = self.traj_embed(past_traj)  # (batch, 8, d_model)\n",
    "        \n",
    "        # Concatenate conditioning\n",
    "        conditioning = torch.cat([traj_tokens, era5_tokens], dim=1)  # (batch, 16, d_model)\n",
    "        conditioning = self.condition_encoder(conditioning)\n",
    "        \n",
    "        # Embed noisy positions\n",
    "        pos_tokens = self.pos_embed(noisy_positions)  # (batch, 5, d_model)\n",
    "        pos_tokens = pos_tokens + self.forecast_pos_embed.unsqueeze(0)\n",
    "        \n",
    "        # Add diffusion timestep\n",
    "        t_embed = self.time_embed(diffusion_t)\n",
    "        pos_tokens = pos_tokens + t_embed.unsqueeze(1)\n",
    "        \n",
    "        # Denoise\n",
    "        denoised = self.denoiser(pos_tokens, conditioning)\n",
    "        predicted_noise = self.output_head(denoised)\n",
    "        \n",
    "        return predicted_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StormDatasetCNN(Dataset):\n",
    "    \"\"\"Dataset that keeps raw ERA5 grids for CNN processing.\"\"\"\n",
    "    \n",
    "    def __init__(self, pkl_file):\n",
    "        with open(pkl_file, 'rb') as f:\n",
    "            self.samples = pickle.load(f)\n",
    "        \n",
    "        # Filter valid samples\n",
    "        self.samples = [\n",
    "            s for s in self.samples \n",
    "            if all(s['targets'][f't+{fh}h'] is not None for fh in [6, 12, 24, 48, 72])\n",
    "        ]\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} valid samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Past trajectory\n",
    "        traj = torch.FloatTensor(sample['input_trajectory'])\n",
    "        \n",
    "        # ERA5 raw data (keep as-is for CNN)\n",
    "        env_data = sample['environmental_data']\n",
    "        \n",
    "        # Target positions\n",
    "        targets = []\n",
    "        for fh in [6, 12, 24, 48, 72]:\n",
    "            t = sample['targets'][f't+{fh}h']\n",
    "            targets.append([t['lat'], t['lon']])\n",
    "        targets = torch.FloatTensor(targets)\n",
    "        \n",
    "        return traj, env_data, targets\n",
    "\n",
    "\n",
    "def collate_fn_cnn(batch):\n",
    "    \"\"\"Custom collate to handle list of dicts in ERA5 data.\"\"\"\n",
    "    trajs, envs, targets = zip(*batch)\n",
    "    \n",
    "    trajs = torch.stack(trajs)\n",
    "    targets = torch.stack(targets)\n",
    "    # envs stays as list of lists of dicts\n",
    "    \n",
    "    return trajs, list(envs), targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Model\n",
    "    'd_model': 256,\n",
    "    'n_heads': 8,\n",
    "    'n_layers': 6,\n",
    "    'dropout': 0.1,\n",
    "    \n",
    "    # Training\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.01,\n",
    "    'n_epochs': 100,\n",
    "    'grad_clip': 1.0,\n",
    "    \n",
    "    # Diffusion\n",
    "    'diffusion_timesteps': 100,\n",
    "    \n",
    "    # Data\n",
    "    'data_path': 'Processed_Data_Subset/processed_samples_1980.pkl',\n",
    "    \n",
    "    # Logging\n",
    "    'log_interval': 10,\n",
    "    'save_interval': 20,\n",
    "    'checkpoint_dir': 'checkpoints',\n",
    "\n",
    "    # Evaluation settings\n",
    "    'eval_interval': 5,      # Evaluate every 5 epochs\n",
    "    'eval_samples': 20,      # Evaluate on 20 samples\n",
    "    'eval_ddim_steps': 50,   # Use 50 DDIM steps (vs 1000 DDPM)\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING WITH WANDB\n",
    "# ============================================================================\n",
    "\n",
    "def train_epoch_logged(model, diffusion, dataloader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    step = 0\n",
    "    \n",
    "    for batch_idx, (traj, env_data, targets) in enumerate(dataloader):\n",
    "        traj = traj.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        batch_size = traj.shape[0]\n",
    "        \n",
    "        # Sample diffusion timesteps\n",
    "        t = torch.randint(0, diffusion.timesteps, (batch_size,), device=device)\n",
    "        \n",
    "        # Add noise\n",
    "        noise = torch.randn_like(targets)\n",
    "        noisy_targets = diffusion.q_sample(targets, t, noise=noise)\n",
    "        \n",
    "        # Forward pass\n",
    "        predicted_noise = model(traj, env_data, noisy_targets, t)\n",
    "        \n",
    "        # Loss\n",
    "        loss = nn.MSELoss()(predicted_noise, noise)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG['grad_clip'])\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        step += 1\n",
    "        \n",
    "        # Log to wandb\n",
    "        if batch_idx % CONFIG['log_interval'] == 0:\n",
    "            wandb.log({\n",
    "                'train/batch_loss': loss.item(),\n",
    "                'train/epoch': epoch,\n",
    "                'train/step': epoch * len(dataloader) + batch_idx,\n",
    "            })\n",
    "            print(f\"  Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def evaluate(model, diffusion, dataset, device, n_samples=50):\n",
    "#     \"\"\"Quick evaluation on a subset.\"\"\"\n",
    "#     model.eval()\n",
    "    \n",
    "#     errors = []\n",
    "    \n",
    "#     for idx in range(min(n_samples, len(dataset))):\n",
    "#         traj, env_data, actual = dataset[idx]\n",
    "        \n",
    "#         # Generate prediction\n",
    "#         pred = diffusion.sample(\n",
    "#             model,\n",
    "#             traj.unsqueeze(0).to(device),\n",
    "#             [env_data],  # Wrap in list for batch\n",
    "#             device\n",
    "#         )\n",
    "        \n",
    "#         pred = pred[0].cpu().numpy()\n",
    "#         actual = actual.numpy()\n",
    "        \n",
    "#         # Calculate 72h error (last position)\n",
    "#         lat_err = (pred[4, 0] - actual[4, 0]) * 111\n",
    "#         lon_err = (pred[4, 1] - actual[4, 1]) * 111 * np.cos(np.radians(actual[4, 0]))\n",
    "#         dist_err = np.sqrt(lat_err**2 + lon_err**2)\n",
    "#         errors.append(dist_err)\n",
    "    \n",
    "#     return np.mean(errors), np.std(errors)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, diffusion, dataset, device, n_samples=20):\n",
    "    \"\"\"Fast evaluation using DDIM sampling.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for idx in range(min(n_samples, len(dataset))):\n",
    "        traj, env_data, actual = dataset[idx]\n",
    "        \n",
    "        # Use DDIM for fast sampling (50 steps instead of 1000)\n",
    "        pred = diffusion.ddim_sample(\n",
    "            model,\n",
    "            traj.unsqueeze(0).to(device),\n",
    "            [env_data],\n",
    "            device,\n",
    "            steps=50  # 20x faster than full sampling!\n",
    "        )\n",
    "        \n",
    "        pred = pred[0].cpu().numpy()\n",
    "        actual = actual.numpy()\n",
    "        \n",
    "        # Calculate 72h error\n",
    "        lat_err = (pred[4, 0] - actual[4, 0]) * 111\n",
    "        lon_err = (pred[4, 1] - actual[4, 1]) * 111 * np.cos(np.radians(actual[4, 0]))\n",
    "        dist_err = np.sqrt(lat_err**2 + lon_err**2)\n",
    "        errors.append(dist_err)\n",
    "    \n",
    "    return np.mean(errors), np.std(errors)\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, scheduler, epoch, loss, filename):\n",
    "    \"\"\"Save checkpoint with all training state.\"\"\"\n",
    "    checkpoint_path = Path(CONFIG['checkpoint_dir']) / filename\n",
    "    checkpoint_path.parent.mkdir(exist_ok=True)\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'loss': loss,\n",
    "        'config': CONFIG,\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "    \n",
    "    # Also save to wandb\n",
    "    wandb.save(str(checkpoint_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▆█</td></tr><tr><td>train/batch_loss</td><td>▇█▂▆▄▃▅▅▄▅▂▃▆██▄▆▃▂▂▁▂▂▂▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▃▃▃▃▃▅▅▅▅▅▆▆▆▆▆█████</td></tr><tr><td>train/epoch_loss</td><td>█▂▁▂</td></tr><tr><td>train/learning_rate</td><td>█▇▅▁</td></tr><tr><td>train/step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_loss</td><td>1.03109</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>train/batch_loss</td><td>0.9343</td></tr><tr><td>train/epoch</td><td>4</td></tr><tr><td>train/epoch_loss</td><td>1.04635</td></tr><tr><td>train/learning_rate</td><td>0.0001</td></tr><tr><td>train/step</td><td>224</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cnn-encoder-256d-6L</strong> at: <a href='https://wandb.ai/shambhavijilkar-cmu/cyclone-diffusion-transformer/runs/86ufj3wk' target=\"_blank\">https://wandb.ai/shambhavijilkar-cmu/cyclone-diffusion-transformer/runs/86ufj3wk</a><br> View project at: <a href='https://wandb.ai/shambhavijilkar-cmu/cyclone-diffusion-transformer' target=\"_blank\">https://wandb.ai/shambhavijilkar-cmu/cyclone-diffusion-transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251209_045532-86ufj3wk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sagemaker-user/TCs_DL_code_dt/wandb/run-20251209_052753-htu5wjav</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shambhavijilkar-cmu/cyclone-diffusion-transformer/runs/htu5wjav' target=\"_blank\">cnn-encoder-256d-6L</a></strong> to <a href='https://wandb.ai/shambhavijilkar-cmu/cyclone-diffusion-transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shambhavijilkar-cmu/cyclone-diffusion-transformer' target=\"_blank\">https://wandb.ai/shambhavijilkar-cmu/cyclone-diffusion-transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shambhavijilkar-cmu/cyclone-diffusion-transformer/runs/htu5wjav' target=\"_blank\">https://wandb.ai/shambhavijilkar-cmu/cyclone-diffusion-transformer/runs/htu5wjav</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using device: cuda\n",
      "   GPU: Tesla T4\n",
      "   Memory: 15.6 GB\n",
      "\n",
      " Loading data...\n",
      "Loaded 727 valid samples\n",
      "\n",
      " Building model...\n",
      "   Parameters: 11.76M\n",
      "\n",
      " Starting training for 100 epochs...\n",
      "======================================================================\n",
      "\n",
      " Epoch 1/100\n",
      "  Batch 0/46, Loss: 1.4081\n",
      "  Batch 10/46, Loss: 1.1226\n",
      "  Batch 20/46, Loss: 1.1075\n",
      "  Batch 30/46, Loss: 0.9606\n",
      "  Batch 40/46, Loss: 1.1020\n",
      "   Train Loss: 1.1296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoints/best_model.pt\n",
      "\n",
      " Epoch 2/100\n",
      "  Batch 0/46, Loss: 1.0963\n",
      "  Batch 10/46, Loss: 1.0645\n",
      "  Batch 20/46, Loss: 0.9546\n",
      "  Batch 30/46, Loss: 0.8338\n",
      "  Batch 40/46, Loss: 1.2151\n",
      "   Train Loss: 1.0147\n",
      "Saved checkpoint: checkpoints/best_model.pt\n",
      "\n",
      " Epoch 3/100\n",
      "  Batch 0/46, Loss: 0.9193\n",
      "  Batch 10/46, Loss: 1.0805\n",
      "  Batch 20/46, Loss: 1.1388\n",
      "  Batch 30/46, Loss: 0.8843\n",
      "  Batch 40/46, Loss: 0.9086\n",
      "   Train Loss: 1.0316\n",
      "\n",
      " Epoch 4/100\n",
      "  Batch 0/46, Loss: 1.0074\n",
      "  Batch 10/46, Loss: 0.9310\n",
      "  Batch 20/46, Loss: 1.0559\n",
      "  Batch 30/46, Loss: 1.0718\n",
      "  Batch 40/46, Loss: 0.7969\n",
      "   Train Loss: 1.0245\n",
      "\n",
      " Epoch 5/100\n",
      "  Batch 0/46, Loss: 1.0596\n",
      "  Batch 10/46, Loss: 0.9815\n",
      "  Batch 20/46, Loss: 0.8802\n",
      "  Batch 30/46, Loss: 1.0010\n",
      "  Batch 40/46, Loss: 1.0398\n",
      "   Eval 72h Error: 12691.3 ± 251.7 km\n",
      "   Train Loss: 1.0211\n",
      "\n",
      " Epoch 6/100\n",
      "  Batch 0/46, Loss: 0.8128\n",
      "  Batch 10/46, Loss: 1.0061\n",
      "  Batch 20/46, Loss: 0.9743\n",
      "  Batch 30/46, Loss: 1.0931\n",
      "  Batch 40/46, Loss: 0.9501\n",
      "   Train Loss: 1.0253\n",
      "\n",
      " Epoch 7/100\n",
      "  Batch 0/46, Loss: 1.0243\n",
      "  Batch 10/46, Loss: 0.9702\n",
      "  Batch 20/46, Loss: 0.8686\n",
      "  Batch 30/46, Loss: 1.1568\n",
      "  Batch 40/46, Loss: 1.2885\n",
      "   Train Loss: 1.0127\n",
      "Saved checkpoint: checkpoints/best_model.pt\n",
      "\n",
      " Epoch 8/100\n",
      "  Batch 0/46, Loss: 1.0183\n",
      "  Batch 10/46, Loss: 0.9790\n",
      "  Batch 20/46, Loss: 0.9709\n",
      "  Batch 30/46, Loss: 0.9576\n",
      "  Batch 40/46, Loss: 1.1207\n",
      "   Train Loss: 1.0192\n",
      "\n",
      " Epoch 9/100\n",
      "  Batch 0/46, Loss: 1.2326\n",
      "  Batch 10/46, Loss: 1.1623\n",
      "  Batch 20/46, Loss: 0.9515\n",
      "  Batch 30/46, Loss: 1.0003\n",
      "  Batch 40/46, Loss: 0.7733\n",
      "   Train Loss: 1.0194\n",
      "\n",
      " Epoch 10/100\n",
      "  Batch 0/46, Loss: 0.9822\n",
      "  Batch 10/46, Loss: 1.0559\n",
      "  Batch 20/46, Loss: 0.8843\n",
      "  Batch 30/46, Loss: 1.0930\n",
      "  Batch 40/46, Loss: 0.9680\n",
      "   Eval 72h Error: 12629.1 ± 268.1 km\n",
      "   Train Loss: 1.0066\n",
      "Saved checkpoint: checkpoints/best_model.pt\n",
      "\n",
      " Epoch 11/100\n",
      "  Batch 0/46, Loss: 0.9349\n",
      "  Batch 10/46, Loss: 0.9439\n",
      "  Batch 20/46, Loss: 0.8728\n",
      "  Batch 30/46, Loss: 0.8449\n",
      "  Batch 40/46, Loss: 0.9820\n",
      "   Train Loss: 1.0214\n",
      "\n",
      " Epoch 12/100\n",
      "  Batch 0/46, Loss: 1.0486\n",
      "  Batch 10/46, Loss: 0.9089\n",
      "  Batch 20/46, Loss: 1.0722\n",
      "  Batch 30/46, Loss: 0.9760\n",
      "  Batch 40/46, Loss: 1.3142\n",
      "   Train Loss: 1.0559\n",
      "\n",
      " Epoch 13/100\n",
      "  Batch 0/46, Loss: 0.9463\n",
      "  Batch 10/46, Loss: 1.0525\n",
      "  Batch 20/46, Loss: 1.2361\n",
      "  Batch 30/46, Loss: 0.8930\n",
      "  Batch 40/46, Loss: 0.9770\n",
      "   Train Loss: 1.0025\n",
      "Saved checkpoint: checkpoints/best_model.pt\n",
      "\n",
      " Epoch 14/100\n",
      "  Batch 0/46, Loss: 0.8917\n",
      "  Batch 10/46, Loss: 0.9444\n",
      "  Batch 20/46, Loss: 1.0369\n",
      "  Batch 30/46, Loss: 0.9499\n",
      "  Batch 40/46, Loss: 1.2084\n",
      "   Train Loss: 1.0215\n",
      "\n",
      " Epoch 15/100\n",
      "  Batch 0/46, Loss: 1.0698\n",
      "  Batch 10/46, Loss: 1.0861\n",
      "  Batch 20/46, Loss: 1.0266\n",
      "  Batch 30/46, Loss: 1.1175\n",
      "  Batch 40/46, Loss: 1.0863\n",
      "   Eval 72h Error: 12603.9 ± 242.4 km\n",
      "   Train Loss: 1.0171\n",
      "\n",
      " Epoch 16/100\n",
      "  Batch 0/46, Loss: 0.8147\n",
      "  Batch 10/46, Loss: 0.9728\n",
      "  Batch 20/46, Loss: 1.0913\n",
      "  Batch 30/46, Loss: 1.1402\n",
      "  Batch 40/46, Loss: 0.9623\n",
      "   Train Loss: 1.0221\n",
      "\n",
      " Epoch 17/100\n",
      "  Batch 0/46, Loss: 1.2068\n",
      "  Batch 10/46, Loss: 1.0222\n",
      "  Batch 20/46, Loss: 0.8757\n",
      "  Batch 30/46, Loss: 1.1883\n",
      "  Batch 40/46, Loss: 1.0222\n",
      "   Train Loss: 0.9665\n",
      "Saved checkpoint: checkpoints/best_model.pt\n",
      "\n",
      " Epoch 18/100\n",
      "  Batch 0/46, Loss: 0.9535\n",
      "  Batch 10/46, Loss: 1.1997\n",
      "  Batch 20/46, Loss: 0.9885\n",
      "  Batch 30/46, Loss: 0.9187\n",
      "  Batch 40/46, Loss: 0.8889\n",
      "   Train Loss: 1.0157\n",
      "\n",
      " Epoch 19/100\n",
      "  Batch 0/46, Loss: 1.1090\n",
      "  Batch 10/46, Loss: 1.0260\n",
      "  Batch 20/46, Loss: 1.0050\n",
      "  Batch 30/46, Loss: 0.8254\n",
      "  Batch 40/46, Loss: 1.0639\n",
      "   Train Loss: 1.0120\n",
      "\n",
      " Epoch 20/100\n",
      "  Batch 0/46, Loss: 0.8501\n",
      "  Batch 10/46, Loss: 0.9569\n",
      "  Batch 20/46, Loss: 1.0401\n",
      "  Batch 30/46, Loss: 1.0094\n",
      "  Batch 40/46, Loss: 1.0266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Eval 72h Error: 12566.5 ± 246.0 km\n",
      "   Train Loss: 0.9724\n",
      "Saved checkpoint: checkpoints/checkpoint_epoch_20.pt\n",
      "\n",
      " Epoch 21/100\n",
      "  Batch 0/46, Loss: 1.0494\n",
      "  Batch 10/46, Loss: 1.0265\n",
      "  Batch 20/46, Loss: 0.9200\n",
      "  Batch 30/46, Loss: 1.0584\n",
      "  Batch 40/46, Loss: 1.0472\n",
      "   Train Loss: 1.0161\n",
      "\n",
      " Epoch 22/100\n",
      "  Batch 0/46, Loss: 1.0970\n",
      "  Batch 10/46, Loss: 0.8061\n",
      "  Batch 20/46, Loss: 1.2029\n",
      "  Batch 30/46, Loss: 1.2116\n",
      "  Batch 40/46, Loss: 0.8526\n",
      "   Train Loss: 1.0069\n",
      "\n",
      " Epoch 23/100\n",
      "  Batch 0/46, Loss: 1.0661\n",
      "  Batch 10/46, Loss: 0.7999\n",
      "  Batch 20/46, Loss: 1.1445\n",
      "  Batch 30/46, Loss: 0.9130\n",
      "  Batch 40/46, Loss: 0.8711\n",
      "   Train Loss: 0.9932\n",
      "\n",
      " Epoch 24/100\n",
      "  Batch 0/46, Loss: 1.1194\n",
      "  Batch 10/46, Loss: 1.1215\n",
      "  Batch 20/46, Loss: 1.0059\n",
      "  Batch 30/46, Loss: 1.0857\n",
      "  Batch 40/46, Loss: 1.0438\n",
      "   Train Loss: 1.0233\n",
      "\n",
      " Epoch 25/100\n",
      "  Batch 0/46, Loss: 1.1407\n",
      "  Batch 10/46, Loss: 1.0373\n",
      "  Batch 20/46, Loss: 1.0280\n",
      "  Batch 30/46, Loss: 0.9946\n",
      "  Batch 40/46, Loss: 0.9544\n",
      "   Eval 72h Error: 12673.5 ± 305.2 km\n",
      "   Train Loss: 0.9912\n",
      "\n",
      " Epoch 26/100\n",
      "  Batch 0/46, Loss: 0.8999\n",
      "  Batch 10/46, Loss: 1.0295\n",
      "  Batch 20/46, Loss: 0.9732\n",
      "  Batch 30/46, Loss: 0.9848\n",
      "  Batch 40/46, Loss: 0.8755\n",
      "   Train Loss: 0.9701\n",
      "\n",
      " Epoch 27/100\n",
      "  Batch 0/46, Loss: 0.8510\n",
      "  Batch 10/46, Loss: 1.0266\n",
      "  Batch 20/46, Loss: 0.9238\n",
      "  Batch 30/46, Loss: 1.1664\n",
      "  Batch 40/46, Loss: 1.0581\n",
      "   Train Loss: 1.0220\n",
      "\n",
      " Epoch 28/100\n",
      "  Batch 0/46, Loss: 0.8072\n",
      "  Batch 10/46, Loss: 0.7826\n",
      "  Batch 20/46, Loss: 1.0513\n",
      "  Batch 30/46, Loss: 1.0548\n",
      "  Batch 40/46, Loss: 0.9775\n",
      "   Train Loss: 0.9633\n",
      "Saved checkpoint: checkpoints/best_model.pt\n",
      "\n",
      " Epoch 29/100\n",
      "  Batch 0/46, Loss: 0.8958\n",
      "  Batch 10/46, Loss: 1.1277\n",
      "  Batch 20/46, Loss: 1.1077\n",
      "  Batch 30/46, Loss: 1.0293\n",
      "  Batch 40/46, Loss: 1.0192\n",
      "   Train Loss: 1.0077\n",
      "\n",
      " Epoch 30/100\n",
      "  Batch 0/46, Loss: 0.9573\n",
      "  Batch 10/46, Loss: 0.8707\n",
      "  Batch 20/46, Loss: 1.1063\n",
      "  Batch 30/46, Loss: 1.0552\n",
      "  Batch 40/46, Loss: 0.8848\n",
      "   Eval 72h Error: 12589.0 ± 302.9 km\n",
      "   Train Loss: 1.0094\n",
      "\n",
      " Epoch 31/100\n",
      "  Batch 0/46, Loss: 1.0987\n",
      "  Batch 10/46, Loss: 0.9844\n",
      "  Batch 20/46, Loss: 0.8883\n",
      "  Batch 30/46, Loss: 0.8626\n",
      "  Batch 40/46, Loss: 1.1043\n",
      "   Train Loss: 0.9966\n",
      "\n",
      " Epoch 32/100\n",
      "  Batch 0/46, Loss: 0.9006\n",
      "  Batch 10/46, Loss: 1.0118\n",
      "  Batch 20/46, Loss: 1.0579\n",
      "  Batch 30/46, Loss: 1.0681\n",
      "  Batch 40/46, Loss: 0.8307\n",
      "   Train Loss: 0.9968\n",
      "\n",
      " Epoch 33/100\n",
      "  Batch 0/46, Loss: 0.9475\n",
      "  Batch 10/46, Loss: 0.8594\n",
      "  Batch 20/46, Loss: 1.0025\n",
      "  Batch 30/46, Loss: 1.1424\n",
      "  Batch 40/46, Loss: 0.9864\n",
      "   Train Loss: 1.0282\n",
      "\n",
      " Epoch 34/100\n",
      "  Batch 0/46, Loss: 1.1055\n",
      "  Batch 10/46, Loss: 1.1031\n",
      "  Batch 20/46, Loss: 0.8930\n",
      "  Batch 30/46, Loss: 1.0816\n",
      "  Batch 40/46, Loss: 0.9424\n",
      "   Train Loss: 0.9980\n",
      "\n",
      " Epoch 35/100\n",
      "  Batch 0/46, Loss: 0.7814\n",
      "  Batch 10/46, Loss: 0.9577\n",
      "  Batch 20/46, Loss: 0.9292\n",
      "  Batch 30/46, Loss: 1.0545\n",
      "  Batch 40/46, Loss: 0.8983\n",
      "   Eval 72h Error: 12689.0 ± 263.5 km\n",
      "   Train Loss: 0.9882\n",
      "\n",
      " Epoch 36/100\n",
      "  Batch 0/46, Loss: 0.9860\n",
      "  Batch 10/46, Loss: 0.8806\n",
      "  Batch 20/46, Loss: 0.8703\n",
      "  Batch 30/46, Loss: 1.0428\n",
      "  Batch 40/46, Loss: 0.8858\n",
      "   Train Loss: 0.9816\n",
      "\n",
      " Epoch 37/100\n",
      "  Batch 0/46, Loss: 1.0830\n",
      "  Batch 10/46, Loss: 1.0942\n",
      "  Batch 20/46, Loss: 1.0342\n",
      "  Batch 30/46, Loss: 1.3210\n",
      "  Batch 40/46, Loss: 1.0425\n",
      "   Train Loss: 1.0073\n",
      "\n",
      " Epoch 38/100\n",
      "  Batch 0/46, Loss: 1.1138\n",
      "  Batch 10/46, Loss: 1.0492\n",
      "  Batch 20/46, Loss: 1.0939\n",
      "  Batch 30/46, Loss: 1.1311\n",
      "  Batch 40/46, Loss: 0.8729\n",
      "   Train Loss: 1.0209\n",
      "\n",
      " Epoch 39/100\n",
      "  Batch 0/46, Loss: 1.0425\n",
      "  Batch 10/46, Loss: 0.9749\n",
      "  Batch 20/46, Loss: 0.9452\n",
      "  Batch 30/46, Loss: 0.9331\n",
      "  Batch 40/46, Loss: 1.3020\n",
      "   Train Loss: 0.9690\n",
      "\n",
      " Epoch 40/100\n",
      "  Batch 0/46, Loss: 0.9988\n",
      "  Batch 10/46, Loss: 1.0429\n",
      "  Batch 20/46, Loss: 0.9586\n",
      "  Batch 30/46, Loss: 0.8755\n",
      "  Batch 40/46, Loss: 1.0016\n",
      "   Eval 72h Error: 12621.6 ± 318.7 km\n",
      "   Train Loss: 0.9894\n",
      "Saved checkpoint: checkpoints/checkpoint_epoch_40.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 41/100\n",
      "  Batch 0/46, Loss: 1.0695\n",
      "  Batch 10/46, Loss: 0.8712\n",
      "  Batch 20/46, Loss: 1.1414\n",
      "  Batch 30/46, Loss: 1.0774\n",
      "  Batch 40/46, Loss: 0.9142\n",
      "   Train Loss: 0.9973\n",
      "\n",
      " Epoch 42/100\n",
      "  Batch 0/46, Loss: 1.2402\n",
      "  Batch 10/46, Loss: 1.0705\n",
      "  Batch 20/46, Loss: 0.9209\n",
      "  Batch 30/46, Loss: 1.1678\n",
      "  Batch 40/46, Loss: 0.9803\n",
      "   Train Loss: 1.0291\n",
      "\n",
      " Epoch 43/100\n",
      "  Batch 0/46, Loss: 0.8584\n",
      "  Batch 10/46, Loss: 1.0534\n",
      "  Batch 20/46, Loss: 0.8491\n",
      "  Batch 30/46, Loss: 0.9446\n",
      "  Batch 40/46, Loss: 1.0508\n",
      "   Train Loss: 1.0074\n",
      "\n",
      " Epoch 44/100\n",
      "  Batch 0/46, Loss: 1.0186\n",
      "  Batch 10/46, Loss: 1.1116\n",
      "  Batch 20/46, Loss: 1.0932\n",
      "  Batch 30/46, Loss: 1.0754\n",
      "  Batch 40/46, Loss: 1.0611\n",
      "   Train Loss: 1.0013\n",
      "\n",
      " Epoch 45/100\n",
      "  Batch 0/46, Loss: 0.9930\n",
      "  Batch 10/46, Loss: 1.0185\n",
      "  Batch 20/46, Loss: 0.8837\n",
      "  Batch 30/46, Loss: 0.8550\n",
      "  Batch 40/46, Loss: 0.8513\n",
      "   Eval 72h Error: 12685.2 ± 243.9 km\n",
      "   Train Loss: 0.9820\n",
      "\n",
      " Epoch 46/100\n",
      "  Batch 0/46, Loss: 1.0768\n",
      "  Batch 10/46, Loss: 0.8352\n",
      "  Batch 20/46, Loss: 1.0781\n",
      "  Batch 30/46, Loss: 0.7310\n",
      "  Batch 40/46, Loss: 0.9298\n",
      "   Train Loss: 0.9995\n",
      "\n",
      " Epoch 47/100\n",
      "  Batch 0/46, Loss: 1.0975\n",
      "  Batch 10/46, Loss: 1.1796\n",
      "  Batch 20/46, Loss: 1.1261\n",
      "  Batch 30/46, Loss: 1.0826\n",
      "  Batch 40/46, Loss: 0.9592\n",
      "   Train Loss: 1.0067\n",
      "\n",
      " Epoch 48/100\n",
      "  Batch 0/46, Loss: 1.0596\n",
      "  Batch 10/46, Loss: 1.0050\n",
      "  Batch 20/46, Loss: 1.0816\n",
      "  Batch 30/46, Loss: 0.8572\n",
      "  Batch 40/46, Loss: 1.3619\n",
      "   Train Loss: 1.0161\n",
      "\n",
      " Epoch 49/100\n",
      "  Batch 0/46, Loss: 0.9983\n",
      "  Batch 10/46, Loss: 0.8927\n",
      "  Batch 20/46, Loss: 0.9358\n",
      "  Batch 30/46, Loss: 0.9435\n",
      "  Batch 40/46, Loss: 0.9754\n",
      "   Train Loss: 0.9944\n",
      "\n",
      " Epoch 50/100\n",
      "  Batch 0/46, Loss: 1.1373\n",
      "  Batch 10/46, Loss: 1.1435\n",
      "  Batch 20/46, Loss: 0.8929\n",
      "  Batch 30/46, Loss: 1.2985\n",
      "  Batch 40/46, Loss: 1.1157\n",
      "   Eval 72h Error: 12672.0 ± 255.6 km\n",
      "   Train Loss: 1.0184\n",
      "\n",
      " Epoch 51/100\n",
      "  Batch 0/46, Loss: 0.9667\n",
      "  Batch 10/46, Loss: 0.7021\n",
      "  Batch 20/46, Loss: 0.8477\n",
      "  Batch 30/46, Loss: 1.2721\n",
      "  Batch 40/46, Loss: 1.1379\n",
      "   Train Loss: 1.0044\n",
      "\n",
      " Epoch 52/100\n",
      "  Batch 0/46, Loss: 0.9426\n",
      "  Batch 10/46, Loss: 0.9704\n",
      "  Batch 20/46, Loss: 0.9579\n",
      "  Batch 30/46, Loss: 0.8719\n",
      "  Batch 40/46, Loss: 0.9459\n",
      "   Train Loss: 0.9971\n",
      "\n",
      " Epoch 53/100\n",
      "  Batch 0/46, Loss: 0.9660\n",
      "  Batch 10/46, Loss: 0.9610\n",
      "  Batch 20/46, Loss: 1.2444\n",
      "  Batch 30/46, Loss: 0.8545\n",
      "  Batch 40/46, Loss: 0.9043\n",
      "   Train Loss: 0.9937\n",
      "\n",
      " Epoch 54/100\n",
      "  Batch 0/46, Loss: 1.0103\n",
      "  Batch 10/46, Loss: 0.8425\n",
      "  Batch 20/46, Loss: 1.0022\n",
      "  Batch 30/46, Loss: 0.9004\n",
      "  Batch 40/46, Loss: 1.0316\n",
      "   Train Loss: 0.9964\n",
      "\n",
      " Epoch 55/100\n",
      "  Batch 0/46, Loss: 1.0784\n",
      "  Batch 10/46, Loss: 0.9068\n",
      "  Batch 20/46, Loss: 0.8742\n",
      "  Batch 30/46, Loss: 0.7947\n",
      "  Batch 40/46, Loss: 0.8773\n",
      "   Eval 72h Error: 12693.5 ± 229.4 km\n",
      "   Train Loss: 0.9601\n",
      "Saved checkpoint: checkpoints/best_model.pt\n",
      "\n",
      " Epoch 56/100\n",
      "  Batch 0/46, Loss: 1.1282\n",
      "  Batch 10/46, Loss: 0.9517\n",
      "  Batch 20/46, Loss: 0.9328\n",
      "  Batch 30/46, Loss: 0.9990\n",
      "  Batch 40/46, Loss: 1.0000\n",
      "   Train Loss: 1.0059\n",
      "\n",
      " Epoch 57/100\n",
      "  Batch 0/46, Loss: 1.0736\n",
      "  Batch 10/46, Loss: 1.1254\n",
      "  Batch 20/46, Loss: 0.8589\n",
      "  Batch 30/46, Loss: 1.2616\n",
      "  Batch 40/46, Loss: 1.0067\n",
      "   Train Loss: 1.0146\n",
      "\n",
      " Epoch 58/100\n",
      "  Batch 0/46, Loss: 0.9277\n",
      "  Batch 10/46, Loss: 0.9947\n",
      "  Batch 20/46, Loss: 0.9555\n",
      "  Batch 30/46, Loss: 0.9312\n",
      "  Batch 40/46, Loss: 0.9415\n",
      "   Train Loss: 0.9857\n",
      "\n",
      " Epoch 59/100\n",
      "  Batch 0/46, Loss: 1.0307\n",
      "  Batch 10/46, Loss: 0.9201\n",
      "  Batch 20/46, Loss: 0.9306\n",
      "  Batch 30/46, Loss: 0.9344\n",
      "  Batch 40/46, Loss: 0.9255\n",
      "   Train Loss: 0.9636\n",
      "\n",
      " Epoch 60/100\n",
      "  Batch 0/46, Loss: 1.0275\n",
      "  Batch 10/46, Loss: 1.1509\n",
      "  Batch 20/46, Loss: 0.8648\n",
      "  Batch 30/46, Loss: 1.0211\n",
      "  Batch 40/46, Loss: 1.1664\n",
      "   Eval 72h Error: 12593.7 ± 334.0 km\n",
      "   Train Loss: 1.0282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: checkpoints/checkpoint_epoch_60.pt\n",
      "\n",
      " Epoch 61/100\n",
      "  Batch 0/46, Loss: 1.0311\n",
      "  Batch 10/46, Loss: 0.8507\n",
      "  Batch 20/46, Loss: 1.0880\n",
      "  Batch 30/46, Loss: 1.0801\n",
      "  Batch 40/46, Loss: 0.8794\n",
      "   Train Loss: 0.9963\n",
      "\n",
      " Epoch 62/100\n",
      "  Batch 0/46, Loss: 0.7921\n",
      "  Batch 10/46, Loss: 0.9192\n",
      "  Batch 20/46, Loss: 0.9847\n",
      "  Batch 30/46, Loss: 0.8829\n",
      "  Batch 40/46, Loss: 0.9399\n",
      "   Train Loss: 0.9990\n",
      "\n",
      " Epoch 63/100\n",
      "  Batch 0/46, Loss: 0.9160\n",
      "  Batch 10/46, Loss: 1.0070\n",
      "  Batch 20/46, Loss: 0.9905\n",
      "  Batch 30/46, Loss: 1.0637\n",
      "  Batch 40/46, Loss: 1.0310\n",
      "   Train Loss: 0.9845\n",
      "\n",
      " Epoch 64/100\n",
      "  Batch 0/46, Loss: 1.1839\n",
      "  Batch 10/46, Loss: 0.9365\n",
      "  Batch 20/46, Loss: 0.9128\n",
      "  Batch 30/46, Loss: 0.9420\n",
      "  Batch 40/46, Loss: 0.9611\n",
      "   Train Loss: 0.9783\n",
      "\n",
      " Epoch 65/100\n",
      "  Batch 0/46, Loss: 0.9728\n",
      "  Batch 10/46, Loss: 1.0348\n",
      "  Batch 20/46, Loss: 0.9546\n",
      "  Batch 30/46, Loss: 0.9931\n",
      "  Batch 40/46, Loss: 0.8564\n",
      "   Eval 72h Error: 12613.4 ± 295.6 km\n",
      "   Train Loss: 1.0053\n",
      "\n",
      " Epoch 66/100\n",
      "  Batch 0/46, Loss: 1.0113\n",
      "  Batch 10/46, Loss: 0.9622\n",
      "  Batch 20/46, Loss: 0.9526\n",
      "  Batch 30/46, Loss: 1.0016\n",
      "  Batch 40/46, Loss: 1.2230\n",
      "   Train Loss: 1.0049\n",
      "\n",
      " Epoch 67/100\n",
      "  Batch 0/46, Loss: 1.1195\n",
      "  Batch 10/46, Loss: 1.0334\n",
      "  Batch 20/46, Loss: 0.9602\n",
      "  Batch 30/46, Loss: 1.0166\n",
      "  Batch 40/46, Loss: 0.8942\n",
      "   Train Loss: 1.0413\n",
      "\n",
      " Epoch 68/100\n",
      "  Batch 0/46, Loss: 0.9530\n",
      "  Batch 10/46, Loss: 0.9669\n",
      "  Batch 20/46, Loss: 1.1084\n",
      "  Batch 30/46, Loss: 0.8842\n",
      "  Batch 40/46, Loss: 1.1013\n",
      "   Train Loss: 1.0071\n",
      "\n",
      " Epoch 69/100\n",
      "  Batch 0/46, Loss: 0.8459\n",
      "  Batch 10/46, Loss: 1.0609\n",
      "  Batch 20/46, Loss: 0.9524\n",
      "  Batch 30/46, Loss: 1.0552\n",
      "  Batch 40/46, Loss: 0.9756\n",
      "   Train Loss: 1.0038\n",
      "\n",
      " Epoch 70/100\n",
      "  Batch 0/46, Loss: 1.0607\n",
      "  Batch 10/46, Loss: 1.0218\n",
      "  Batch 20/46, Loss: 1.1234\n",
      "  Batch 30/46, Loss: 0.9096\n",
      "  Batch 40/46, Loss: 0.8252\n",
      "   Eval 72h Error: 12624.1 ± 260.5 km\n",
      "   Train Loss: 0.9765\n",
      "\n",
      " Epoch 71/100\n",
      "  Batch 0/46, Loss: 0.9211\n",
      "  Batch 10/46, Loss: 0.9088\n",
      "  Batch 20/46, Loss: 0.9774\n",
      "  Batch 30/46, Loss: 1.0736\n",
      "  Batch 40/46, Loss: 1.0359\n",
      "   Train Loss: 0.9884\n",
      "\n",
      " Epoch 72/100\n",
      "  Batch 0/46, Loss: 0.9337\n",
      "  Batch 10/46, Loss: 1.0363\n",
      "  Batch 20/46, Loss: 0.9618\n",
      "  Batch 30/46, Loss: 1.0840\n",
      "  Batch 40/46, Loss: 0.9715\n",
      "   Train Loss: 0.9783\n",
      "\n",
      " Epoch 73/100\n",
      "  Batch 0/46, Loss: 0.9759\n",
      "  Batch 10/46, Loss: 1.0725\n",
      "  Batch 20/46, Loss: 0.9805\n",
      "  Batch 30/46, Loss: 0.9368\n",
      "  Batch 40/46, Loss: 0.8948\n",
      "   Train Loss: 1.0046\n",
      "\n",
      " Epoch 74/100\n",
      "  Batch 0/46, Loss: 0.8214\n",
      "  Batch 10/46, Loss: 0.8549\n",
      "  Batch 20/46, Loss: 1.0304\n",
      "  Batch 30/46, Loss: 0.8745\n",
      "  Batch 40/46, Loss: 1.0732\n",
      "   Train Loss: 0.9903\n",
      "\n",
      " Epoch 75/100\n",
      "  Batch 0/46, Loss: 1.0960\n",
      "  Batch 10/46, Loss: 1.0166\n",
      "  Batch 20/46, Loss: 0.9791\n",
      "  Batch 30/46, Loss: 0.9850\n",
      "  Batch 40/46, Loss: 0.7799\n",
      "   Eval 72h Error: 12648.7 ± 294.7 km\n",
      "   Train Loss: 0.9927\n",
      "\n",
      " Epoch 76/100\n",
      "  Batch 0/46, Loss: 1.1135\n",
      "  Batch 10/46, Loss: 0.9446\n",
      "  Batch 20/46, Loss: 0.8038\n",
      "  Batch 30/46, Loss: 0.8375\n",
      "  Batch 40/46, Loss: 1.1387\n",
      "   Train Loss: 0.9991\n",
      "\n",
      " Epoch 77/100\n",
      "  Batch 0/46, Loss: 1.1248\n",
      "  Batch 10/46, Loss: 0.9664\n",
      "  Batch 20/46, Loss: 0.9447\n",
      "  Batch 30/46, Loss: 0.9687\n",
      "  Batch 40/46, Loss: 0.9721\n",
      "   Train Loss: 0.9855\n",
      "\n",
      " Epoch 78/100\n",
      "  Batch 0/46, Loss: 1.1077\n",
      "  Batch 10/46, Loss: 1.1250\n",
      "  Batch 20/46, Loss: 0.7394\n",
      "  Batch 30/46, Loss: 0.9697\n",
      "  Batch 40/46, Loss: 1.0800\n",
      "   Train Loss: 0.9867\n",
      "\n",
      " Epoch 79/100\n",
      "  Batch 0/46, Loss: 1.0364\n",
      "  Batch 10/46, Loss: 1.1014\n",
      "  Batch 20/46, Loss: 1.0557\n",
      "  Batch 30/46, Loss: 0.8412\n",
      "  Batch 40/46, Loss: 0.9729\n",
      "   Train Loss: 0.9903\n",
      "\n",
      " Epoch 80/100\n",
      "  Batch 0/46, Loss: 0.9064\n",
      "  Batch 10/46, Loss: 0.9294\n",
      "  Batch 20/46, Loss: 0.7933\n",
      "  Batch 30/46, Loss: 0.9072\n",
      "  Batch 40/46, Loss: 1.0137\n",
      "   Eval 72h Error: 12687.2 ± 290.4 km\n",
      "   Train Loss: 0.9870\n",
      "Saved checkpoint: checkpoints/checkpoint_epoch_80.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 81/100\n",
      "  Batch 0/46, Loss: 1.0137\n",
      "  Batch 10/46, Loss: 0.9562\n",
      "  Batch 20/46, Loss: 0.9981\n",
      "  Batch 30/46, Loss: 1.3419\n",
      "  Batch 40/46, Loss: 0.9127\n",
      "   Train Loss: 0.9893\n",
      "\n",
      " Epoch 82/100\n",
      "  Batch 0/46, Loss: 1.0505\n",
      "  Batch 10/46, Loss: 0.7879\n",
      "  Batch 20/46, Loss: 1.1129\n",
      "  Batch 30/46, Loss: 1.0908\n",
      "  Batch 40/46, Loss: 1.0641\n",
      "   Train Loss: 1.0171\n",
      "\n",
      " Epoch 83/100\n",
      "  Batch 0/46, Loss: 0.9512\n",
      "  Batch 10/46, Loss: 1.0176\n",
      "  Batch 20/46, Loss: 1.0834\n",
      "  Batch 30/46, Loss: 1.1693\n",
      "  Batch 40/46, Loss: 1.0333\n",
      "   Train Loss: 0.9799\n",
      "\n",
      " Epoch 84/100\n",
      "  Batch 0/46, Loss: 1.0027\n",
      "  Batch 10/46, Loss: 1.0031\n",
      "  Batch 20/46, Loss: 0.9873\n",
      "  Batch 30/46, Loss: 0.9598\n",
      "  Batch 40/46, Loss: 1.0679\n",
      "   Train Loss: 0.9567\n",
      "Saved checkpoint: checkpoints/best_model.pt\n",
      "\n",
      " Epoch 85/100\n",
      "  Batch 0/46, Loss: 0.9126\n",
      "  Batch 10/46, Loss: 0.9828\n",
      "  Batch 20/46, Loss: 0.8955\n",
      "  Batch 30/46, Loss: 0.8981\n",
      "  Batch 40/46, Loss: 0.9245\n",
      "   Eval 72h Error: 12573.4 ± 287.7 km\n",
      "   Train Loss: 0.9529\n",
      "Saved checkpoint: checkpoints/best_model.pt\n",
      "\n",
      " Epoch 86/100\n",
      "  Batch 0/46, Loss: 0.8560\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch_logged\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_interval\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     75\u001b[0m     eval_mean, eval_std \u001b[38;5;241m=\u001b[39m evaluate(model, diffusion, dataset, device, \n\u001b[1;32m     76\u001b[0m                                   n_samples\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_samples\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[27], line 75\u001b[0m, in \u001b[0;36mtrain_epoch_logged\u001b[0;34m(model, diffusion, dataloader, optimizer, device, epoch)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m     74\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 75\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad_clip\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     77\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize wandb\n",
    "wandb.init(\n",
    "    project=\"cyclone-diffusion-transformer\",\n",
    "    config=CONFIG,\n",
    "    name=f\"cnn-encoder-{CONFIG['d_model']}d-{CONFIG['n_layers']}L\",\n",
    ")\n",
    "\n",
    "# Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"  Using device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Load data\n",
    "print(f\"\\n Loading data...\")\n",
    "dataset = StormDatasetCNN(CONFIG['data_path'])\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn_cnn\n",
    ")\n",
    "\n",
    "# Create model\n",
    "print(f\"\\n Building model...\")\n",
    "model = DiffusionTransformerCNN(\n",
    "    d_model=CONFIG['d_model'],\n",
    "    n_heads=CONFIG['n_heads'],\n",
    "    n_layers=CONFIG['n_layers'],\n",
    "    dropout=CONFIG['dropout']\n",
    ").to(device)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"   Parameters: {n_params/1e6:.2f}M\")\n",
    "wandb.config.update({'n_parameters': n_params})\n",
    "\n",
    "# Watch model gradients in wandb\n",
    "wandb.watch(model, log='all', log_freq=100)\n",
    "\n",
    "# Diffusion\n",
    "diffusion = GaussianDiffusion(timesteps=CONFIG['diffusion_timesteps'])\n",
    "diffusion.betas = diffusion.betas.to(device)\n",
    "diffusion.alphas_cumprod = diffusion.alphas_cumprod.to(device)\n",
    "diffusion.alphas_cumprod_prev = diffusion.alphas_cumprod_prev.to(device)\n",
    "diffusion.sqrt_alphas_cumprod = diffusion.sqrt_alphas_cumprod.to(device)\n",
    "diffusion.sqrt_one_minus_alphas_cumprod = diffusion.sqrt_one_minus_alphas_cumprod.to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=CONFIG['n_epochs']\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "print(f\"\\n Starting training for {CONFIG['n_epochs']} epochs...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(CONFIG['n_epochs']):\n",
    "    print(f\"\\n Epoch {epoch+1}/{CONFIG['n_epochs']}\")\n",
    "    \n",
    "    # Train\n",
    "    avg_loss = train_epoch_logged(model, diffusion, dataloader, optimizer, device, epoch)\n",
    "    \n",
    "    if (epoch + 1) % CONFIG['eval_interval'] == 0:\n",
    "        eval_mean, eval_std = evaluate(model, diffusion, dataset, device, \n",
    "                                      n_samples=CONFIG['eval_samples'])\n",
    "        \n",
    "        wandb.log({\n",
    "            'eval/72h_error_mean_km': eval_mean,\n",
    "            'eval/72h_error_std_km': eval_std,\n",
    "        })\n",
    "        print(f\"   Eval 72h Error: {eval_mean:.1f} ± {eval_std:.1f} km\")\n",
    "    \n",
    "    # Log training metrics\n",
    "    wandb.log({\n",
    "        'train/epoch_loss': avg_loss,\n",
    "        'train/learning_rate': optimizer.param_groups[0]['lr'],\n",
    "        'epoch': epoch,\n",
    "    })\n",
    "    print(f\"   Train Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Step scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save best model\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        save_checkpoint(model, optimizer, scheduler, epoch, avg_loss, 'best_model.pt')\n",
    "        wandb.run.summary[\"best_loss\"] = best_loss\n",
    "        wandb.run.summary[\"best_epoch\"] = epoch\n",
    "    \n",
    "    # Regular checkpoints\n",
    "    if (epoch + 1) % CONFIG['save_interval'] == 0:\n",
    "        save_checkpoint(\n",
    "            model, optimizer, scheduler, epoch, avg_loss,\n",
    "            f'checkpoint_epoch_{epoch+1}.pt'\n",
    "        )\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ Training complete!\")\n",
    "print(f\"   Best loss: {best_loss:.4f}\")\n",
    "\n",
    "# Save final model\n",
    "save_checkpoint(model, optimizer, scheduler, CONFIG['n_epochs']-1, avg_loss, 'final_model.pt')\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRUCNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GRU-CNN Baseline from Original Paper\n",
    "Adapted to work with our .pkl data format\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class GRUCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    GRU-CNN model from the paper.\n",
    "    \n",
    "    Architecture:\n",
    "    1. CNN encodes ERA5 spatial fields at each timestep\n",
    "    2. GRU processes sequence of (trajectory + ERA5 embeddings)\n",
    "    3. Decoder predicts future positions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim=128,\n",
    "        num_layers=2,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN encoder for ERA5 (same as our diffusion model)\n",
    "        self.era5_encoder = ERA5CNNEncoder(output_dim=hidden_dim)\n",
    "        \n",
    "        # Trajectory encoder\n",
    "        self.traj_encoder = nn.Linear(6, hidden_dim)\n",
    "        \n",
    "        # GRU for sequence processing\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=hidden_dim * 2,  # traj + era5\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Decoder: predict 5 future positions (10 values: 5 × [lat, lon])\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 10)  # 5 positions × 2 coords\n",
    "        )\n",
    "    \n",
    "    def forward(self, past_traj, env_data_batch):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            past_traj: (batch, 8, 6) - past trajectory\n",
    "            env_data_batch: list of env data for CNN\n",
    "        \n",
    "        Returns:\n",
    "            predictions: (batch, 5, 2) - predicted future positions\n",
    "        \"\"\"\n",
    "        batch_size = past_traj.shape[0]\n",
    "        \n",
    "        # Encode ERA5\n",
    "        era5_features = self.era5_encoder(env_data_batch)  # (batch, 8, hidden_dim)\n",
    "        \n",
    "        # Encode trajectory\n",
    "        traj_features = self.traj_encoder(past_traj)  # (batch, 8, hidden_dim)\n",
    "        \n",
    "        # Combine features\n",
    "        combined = torch.cat([traj_features, era5_features], dim=-1)  # (batch, 8, hidden_dim*2)\n",
    "        \n",
    "        # GRU processes sequence\n",
    "        gru_out, _ = self.gru(combined)  # (batch, 8, hidden_dim)\n",
    "        \n",
    "        # Use last timestep to predict future\n",
    "        last_hidden = gru_out[:, -1, :]  # (batch, hidden_dim)\n",
    "        \n",
    "        # Decode to future positions\n",
    "        predictions = self.decoder(last_hidden)  # (batch, 10)\n",
    "        predictions = predictions.view(batch_size, 5, 2)  # (batch, 5, 2)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Training function for GRU-CNN\n",
    "def train_epoch_grucnn(model, dataloader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (traj, env_data, targets) in enumerate(dataloader):\n",
    "        traj = traj.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(traj, env_data)\n",
    "        \n",
    "        # Loss: MSE on position predictions\n",
    "        loss = nn.MSELoss()(predictions, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            wandb.log({\n",
    "                'grucnn/batch_loss': loss.item(),\n",
    "                'grucnn/epoch': epoch,\n",
    "                'grucnn/step': epoch * len(dataloader) + batch_idx,\n",
    "            })\n",
    "            print(f\"  Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_grucnn(model, dataset, device, n_samples=20):\n",
    "    \"\"\"Evaluate GRU-CNN model.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for idx in range(min(n_samples, len(dataset))):\n",
    "        traj, env_data, actual = dataset[idx]\n",
    "        \n",
    "        # Predict\n",
    "        pred = model(traj.unsqueeze(0).to(device), [env_data])\n",
    "        pred = pred[0].cpu().numpy()\n",
    "        actual = actual.numpy()\n",
    "        \n",
    "        # Calculate 72h error\n",
    "        lat_err = (pred[4, 0] - actual[4, 0]) * 111\n",
    "        lon_err = (pred[4, 1] - actual[4, 1]) * 111 * np.cos(np.radians(actual[4, 0]))\n",
    "        dist_err = np.sqrt(lat_err**2 + lon_err**2)\n",
    "        errors.append(dist_err)\n",
    "    \n",
    "    return np.mean(errors), np.std(errors)\n",
    "\n",
    "\n",
    "def train_grucnn_baseline():\n",
    "    \"\"\"Main training loop for GRU-CNN baseline.\"\"\"\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Training GRU-CNN Baseline on {device}\")\n",
    "    \n",
    "    # Initialize wandb\n",
    "    wandb.init(\n",
    "        project=\"cyclone-diffusion-transformer\",\n",
    "        name=\"grucnn-baseline\",\n",
    "        config={\n",
    "            'model': 'GRU-CNN',\n",
    "            'hidden_dim': 128,\n",
    "            'num_layers': 2,\n",
    "            'learning_rate': 1e-3,\n",
    "            'batch_size': 16,\n",
    "            'n_epochs': 100,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Load data (same as diffusion model)\n",
    "    dataset = StormDatasetCNN('Processed_Data_Subset/processed_samples_1980.pkl')\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        collate_fn=collate_fn_cnn\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = GRUCNN(hidden_dim=128, num_layers=2).to(device)\n",
    "    print(f\"Parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "    \n",
    "    # Training\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        print(f\"\\nEpoch {epoch+1}/100\")\n",
    "        \n",
    "        # Train\n",
    "        avg_loss = train_epoch_grucnn(model, dataloader, optimizer, device, epoch)\n",
    "        \n",
    "        # Evaluate every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            eval_mean, eval_std = evaluate_grucnn(model, dataset, device, n_samples=20)\n",
    "            wandb.log({\n",
    "                'grucnn/eval_72h_error_km': eval_mean,\n",
    "                'grucnn/eval_72h_error_std_km': eval_std,\n",
    "            })\n",
    "            print(f\"   Eval 72h Error: {eval_mean:.1f} ± {eval_std:.1f} km\")\n",
    "        \n",
    "        wandb.log({\n",
    "            'grucnn/epoch_loss': avg_loss,\n",
    "            'grucnn/learning_rate': optimizer.param_groups[0]['lr'],\n",
    "        })\n",
    "        print(f\"   Train Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save best\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save(model.state_dict(), 'grucnn_best.pt')\n",
    "            print(f\"✓ Saved best model\")\n",
    "    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comprehensive Model Comparison\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def comprehensive_evaluation(diffusion_model, grucnn_model, diffusion_obj, dataset, device):\n",
    "    \"\"\"\n",
    "    Evaluate both models on all metrics for comparison.\n",
    "    \"\"\"\n",
    "    diffusion_model.eval()\n",
    "    grucnn_model.eval()\n",
    "    \n",
    "    results = {\n",
    "        'sample_id': [],\n",
    "        'horizon': [],\n",
    "        'diffusion_error_km': [],\n",
    "        'grucnn_error_km': [],\n",
    "        'cyclone_name': [],\n",
    "        'actual_lat': [],\n",
    "        'actual_lon': [],\n",
    "        'diffusion_lat': [],\n",
    "        'diffusion_lon': [],\n",
    "        'grucnn_lat': [],\n",
    "        'grucnn_lon': [],\n",
    "    }\n",
    "    \n",
    "    print(\"Running comprehensive evaluation...\")\n",
    "    \n",
    "    for idx in range(len(dataset)):\n",
    "        traj, env_data, actual = dataset[idx]\n",
    "        sample = dataset.samples[idx]\n",
    "        \n",
    "        # Diffusion prediction (DDIM for speed)\n",
    "        with torch.no_grad():\n",
    "            diff_pred = diffusion_obj.ddim_sample(\n",
    "                diffusion_model,\n",
    "                traj.unsqueeze(0).to(device),\n",
    "                [env_data],\n",
    "                device,\n",
    "                steps=50\n",
    "            )[0].cpu().numpy()\n",
    "        \n",
    "        # GRU-CNN prediction\n",
    "        with torch.no_grad():\n",
    "            gru_pred = grucnn_model(\n",
    "                traj.unsqueeze(0).to(device),\n",
    "                [env_data]\n",
    "            )[0].cpu().numpy()\n",
    "        \n",
    "        actual_np = actual.numpy()\n",
    "        \n",
    "        # Calculate errors for each horizon\n",
    "        for i, horizon in enumerate([6, 12, 24, 48, 72]):\n",
    "            # Diffusion error\n",
    "            diff_lat_err = (diff_pred[i, 0] - actual_np[i, 0]) * 111\n",
    "            diff_lon_err = (diff_pred[i, 1] - actual_np[i, 1]) * 111 * np.cos(np.radians(actual_np[i, 0]))\n",
    "            diff_err = np.sqrt(diff_lat_err**2 + diff_lon_err**2)\n",
    "            \n",
    "            # GRU-CNN error\n",
    "            gru_lat_err = (gru_pred[i, 0] - actual_np[i, 0]) * 111\n",
    "            gru_lon_err = (gru_pred[i, 1] - actual_np[i, 1]) * 111 * np.cos(np.radians(actual_np[i, 0]))\n",
    "            gru_err = np.sqrt(gru_lat_err**2 + gru_lon_err**2)\n",
    "            \n",
    "            results['sample_id'].append(idx)\n",
    "            results['horizon'].append(horizon)\n",
    "            results['diffusion_error_km'].append(diff_err)\n",
    "            results['grucnn_error_km'].append(gru_err)\n",
    "            results['cyclone_name'].append(sample['cyclone_name'])\n",
    "            results['actual_lat'].append(actual_np[i, 0])\n",
    "            results['actual_lon'].append(actual_np[i, 1])\n",
    "            results['diffusion_lat'].append(diff_pred[i, 0])\n",
    "            results['diffusion_lon'].append(diff_pred[i, 1])\n",
    "            results['grucnn_lat'].append(gru_pred[i, 0])\n",
    "            results['grucnn_lon'].append(gru_pred[i, 1])\n",
    "        \n",
    "        if (idx + 1) % 50 == 0:\n",
    "            print(f\"  Evaluated {idx+1}/{len(dataset)} samples\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def create_comparison_table(df):\n",
    "    \"\"\"Create publication-quality comparison table.\"\"\"\n",
    "    \n",
    "    summary = df.groupby('horizon').agg({\n",
    "        'diffusion_error_km': ['mean', 'std'],\n",
    "        'grucnn_error_km': ['mean', 'std']\n",
    "    }).round(1)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MODEL COMPARISON: Track Error (km)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Horizon':<10} {'Diffusion Transformer':<30} {'GRU-CNN Baseline':<30}\")\n",
    "    print(f\"{'(hours)':<10} {'Mean ± Std':<30} {'Mean ± Std':<30}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for horizon in [6, 12, 24, 48, 72]:\n",
    "        diff_mean = summary.loc[horizon, ('diffusion_error_km', 'mean')]\n",
    "        diff_std = summary.loc[horizon, ('diffusion_error_km', 'std')]\n",
    "        gru_mean = summary.loc[horizon, ('grucnn_error_km', 'mean')]\n",
    "        gru_std = summary.loc[horizon, ('grucnn_error_km', 'std')]\n",
    "        \n",
    "        diff_str = f\"{diff_mean:.1f} ± {diff_std:.1f}\"\n",
    "        gru_str = f\"{gru_mean:.1f} ± {gru_std:.1f}\"\n",
    "        \n",
    "        # Highlight winner\n",
    "        winner = \"✓\" if diff_mean < gru_mean else \"\"\n",
    "        \n",
    "        print(f\"{horizon:<10} {diff_str:<30} {gru_str:<30} {winner}\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "\n",
    "def plot_model_comparison(df):\n",
    "    \"\"\"Create comparison visualizations.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Error by horizon\n",
    "    ax = axes[0, 0]\n",
    "    horizons = [6, 12, 24, 48, 72]\n",
    "    diff_means = [df[df['horizon']==h]['diffusion_error_km'].mean() for h in horizons]\n",
    "    gru_means = [df[df['horizon']==h]['grucnn_error_km'].mean() for h in horizons]\n",
    "    \n",
    "    ax.plot(horizons, diff_means, 'o-', linewidth=2, markersize=8, label='Diffusion Transformer')\n",
    "    ax.plot(horizons, gru_means, 's-', linewidth=2, markersize=8, label='GRU-CNN')\n",
    "    ax.set_xlabel('Forecast Horizon (hours)', fontsize=12)\n",
    "    ax.set_ylabel('Mean Track Error (km)', fontsize=12)\n",
    "    ax.set_title('Track Error by Forecast Horizon', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Error distribution comparison\n",
    "    ax = axes[0, 1]\n",
    "    df_72h = df[df['horizon'] == 72]\n",
    "    ax.boxplot([df_72h['diffusion_error_km'], df_72h['grucnn_error_km']], \n",
    "               labels=['Diffusion', 'GRU-CNN'])\n",
    "    ax.set_ylabel('72h Track Error (km)', fontsize=12)\n",
    "    ax.set_title('72-hour Forecast Error Distribution', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 3. Scatter plot: Diffusion vs GRU-CNN\n",
    "    ax = axes[1, 0]\n",
    "    df_72h = df[df['horizon'] == 72]\n",
    "    ax.scatter(df_72h['grucnn_error_km'], df_72h['diffusion_error_km'], alpha=0.5)\n",
    "    max_err = max(df_72h['grucnn_error_km'].max(), df_72h['diffusion_error_km'].max())\n",
    "    ax.plot([0, max_err], [0, max_err], 'r--', alpha=0.5, label='Equal performance')\n",
    "    ax.set_xlabel('GRU-CNN Error (km)', fontsize=12)\n",
    "    ax.set_ylabel('Diffusion Transformer Error (km)', fontsize=12)\n",
    "    ax.set_title('72h: Per-Sample Error Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Improvement histogram\n",
    "    ax = axes[1, 1]\n",
    "    df_72h['improvement'] = df_72h['grucnn_error_km'] - df_72h['diffusion_error_km']\n",
    "    ax.hist(df_72h['improvement'], bins=30, edgecolor='black')\n",
    "    ax.axvline(0, color='red', linestyle='--', linewidth=2, label='No improvement')\n",
    "    ax.set_xlabel('Error Reduction (km)', fontsize=12)\n",
    "    ax.set_ylabel('Number of Samples', fontsize=12)\n",
    "    ax.set_title('72h: Error Reduction Distribution\\n(Positive = Diffusion Better)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_sample_tracks_comparison(df, dataset, sample_indices=[0, 10, 20]):\n",
    "    \"\"\"Plot side-by-side track comparisons for specific samples.\"\"\"\n",
    "    \n",
    "    n_samples = len(sample_indices)\n",
    "    fig = plt.figure(figsize=(18, 6*n_samples))\n",
    "    \n",
    "    for plot_idx, sample_idx in enumerate(sample_indices):\n",
    "        traj, env_data, actual = dataset[sample_idx]\n",
    "        sample_data = df[df['sample_id'] == sample_idx]\n",
    "        \n",
    "        ax = plt.subplot(n_samples, 1, plot_idx+1, projection=ccrs.PlateCarree())\n",
    "        ax.coastlines()\n",
    "        ax.add_feature(cfeature.LAND, alpha=0.3)\n",
    "        ax.add_feature(cfeature.OCEAN, alpha=0.3)\n",
    "        ax.gridlines(draw_labels=True)\n",
    "        \n",
    "        # Past trajectory\n",
    "        past_lats = traj[:, 0].numpy()\n",
    "        past_lons = traj[:, 1].numpy()\n",
    "        ax.plot(past_lons, past_lats, 'o-', color='black', linewidth=2, \n",
    "                markersize=6, label='Past 24h', transform=ccrs.PlateCarree())\n",
    "        \n",
    "        # Actual\n",
    "        actual_data = sample_data[sample_data['horizon'].isin([6, 12, 24, 48, 72])]\n",
    "        actual_lats = actual_data['actual_lat'].values\n",
    "        actual_lons = actual_data['actual_lon'].values\n",
    "        full_actual_lats = np.concatenate([past_lats[-1:], actual_lats])\n",
    "        full_actual_lons = np.concatenate([past_lons[-1:], actual_lons])\n",
    "        ax.plot(full_actual_lons, full_actual_lats, 's-', color='green', \n",
    "                linewidth=2, markersize=8, label='Actual', transform=ccrs.PlateCarree())\n",
    "        \n",
    "        # Diffusion\n",
    "        diff_lats = actual_data['diffusion_lat'].values\n",
    "        diff_lons = actual_data['diffusion_lon'].values\n",
    "        full_diff_lats = np.concatenate([past_lats[-1:], diff_lats])\n",
    "        full_diff_lons = np.concatenate([past_lons[-1:], diff_lons])\n",
    "        ax.plot(full_diff_lons, full_diff_lats, '^-', color='red', \n",
    "                linewidth=2, markersize=8, label='Diffusion', transform=ccrs.PlateCarree())\n",
    "        \n",
    "        # GRU-CNN\n",
    "        gru_lats = actual_data['grucnn_lat'].values\n",
    "        gru_lons = actual_data['grucnn_lon'].values\n",
    "        full_gru_lats = np.concatenate([past_lats[-1:], gru_lats])\n",
    "        full_gru_lons = np.concatenate([past_lons[-1:], gru_lons])\n",
    "        ax.plot(full_gru_lons, full_gru_lats, 'D-', color='blue', \n",
    "                linewidth=2, markersize=8, label='GRU-CNN', transform=ccrs.PlateCarree())\n",
    "        \n",
    "        # Calculate 72h errors\n",
    "        diff_72h_err = sample_data[sample_data['horizon']==72]['diffusion_error_km'].values[0]\n",
    "        gru_72h_err = sample_data[sample_data['horizon']==72]['grucnn_error_km'].values[0]\n",
    "        \n",
    "        ax.legend(loc='upper right')\n",
    "        ax.set_title(f\"Sample {sample_idx} | 72h Error: Diffusion={diff_72h_err:.0f}km, GRU-CNN={gru_72h_err:.0f}km\",\n",
    "                    fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Set extent\n",
    "        all_lats = np.concatenate([past_lats, actual_lats, diff_lats, gru_lats])\n",
    "        all_lons = np.concatenate([past_lons, actual_lons, diff_lons, gru_lons])\n",
    "        margin = 3\n",
    "        ax.set_extent([all_lons.min()-margin, all_lons.max()+margin,\n",
    "                      all_lats.min()-margin, all_lats.max()+margin])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('track_comparison_samples.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
