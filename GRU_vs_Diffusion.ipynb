{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding (Same as vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "class SinusoidalPositionEmbedding(nn.Module):\n",
    "    \"\"\"Timestep embedding for diffusion process.\"\"\"\n",
    "    \n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, t):\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = t[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusion:\n",
    "    \"\"\"\n",
    "    Simplified DDPM for storm track forecasting.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, timesteps=1000, beta_start=0.0001, beta_end=0.02):\n",
    "        self.timesteps = timesteps\n",
    "        \n",
    "        # Linear beta schedule\n",
    "        self.betas = torch.linspace(beta_start, beta_end, timesteps)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "        \n",
    "        # Calculations for diffusion q(x_t | x_{t-1})\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
    "        \n",
    "        # Calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        self.posterior_variance = (\n",
    "            self.betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "    \n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        \"\"\"\n",
    "        Forward diffusion: add noise to clean data.\n",
    "        \n",
    "        Args:\n",
    "            x_start: (batch, 5, 2) - clean future positions\n",
    "            t: (batch,) - diffusion timestep\n",
    "            noise: optional noise to add\n",
    "        \n",
    "        Returns:\n",
    "            x_t: noisy version of x_start at timestep t\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "        \n",
    "        sqrt_alpha = self.sqrt_alphas_cumprod[t]\n",
    "        sqrt_one_minus_alpha = self.sqrt_one_minus_alphas_cumprod[t]\n",
    "        \n",
    "        # Reshape for broadcasting\n",
    "        sqrt_alpha = sqrt_alpha[:, None, None]\n",
    "        sqrt_one_minus_alpha = sqrt_one_minus_alpha[:, None, None]\n",
    "        \n",
    "        return sqrt_alpha * x_start + sqrt_one_minus_alpha * noise\n",
    "    \n",
    "    def p_sample(self, model, x_t, t, past_traj, era5_features):\n",
    "        \"\"\"\n",
    "        Reverse diffusion: denoise one step.\n",
    "        \n",
    "        Args:\n",
    "            model: DiffusionTransformer\n",
    "            x_t: (batch, 5, 2) - noisy positions at timestep t\n",
    "            t: (batch,) - current timestep\n",
    "            past_traj: (batch, 8, 6) - conditioning\n",
    "            era5_features: (batch, 8, 10) - conditioning\n",
    "        \n",
    "        Returns:\n",
    "            x_{t-1}: less noisy positions\n",
    "        \"\"\"\n",
    "        # Predict noise\n",
    "        predicted_noise = model(past_traj, era5_features, x_t, t)\n",
    "        device = x_t.device\n",
    "\n",
    "        # Calculate x_0 prediction\n",
    "        alpha = self.alphas_cumprod.to(device)[t][:, None, None]\n",
    "        alpha_prev = self.alphas_cumprod_prev.to(device)[t][:, None, None]\n",
    "        beta = self.betas.to(device)[t][:, None, None]\n",
    "        \n",
    "        # Predict x_0\n",
    "        pred_x0 = (x_t - torch.sqrt(1 - alpha) * predicted_noise) / torch.sqrt(alpha)\n",
    "        \n",
    "        # Calculate x_{t-1}\n",
    "        alphas_t = self.alphas.to(device)[t][:, None, None]\n",
    "        mean = (\n",
    "            torch.sqrt(alpha_prev) * beta * pred_x0 +\n",
    "            torch.sqrt(alphas_t) * (1 - alpha_prev) * x_t\n",
    "        ) / (1 - alpha)\n",
    "        \n",
    "        if t[0] > 0:\n",
    "            noise = torch.randn_like(x_t)\n",
    "            variance = self.posterior_variance.to(device)[t][:, None, None]\n",
    "            return mean + torch.sqrt(variance) * noise\n",
    "        else:\n",
    "            return mean\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample(self, model, past_traj, era5_features, device):\n",
    "        \"\"\"\n",
    "        Generate storm track by denoising from pure noise.\n",
    "        \n",
    "        Args:\n",
    "            model: trained DiffusionTransformer\n",
    "            past_traj: (batch, 8, 6)\n",
    "            era5_features: (batch, 8, 10)\n",
    "        \n",
    "        Returns:\n",
    "            predicted_track: (batch, 5, 2) - forecasted positions\n",
    "        \"\"\"\n",
    "        batch_size = past_traj.shape[0]\n",
    "        \n",
    "        # Start from pure noise\n",
    "        x = torch.randn(batch_size, 5, 2, device=device)\n",
    "        \n",
    "        # Iteratively denoise\n",
    "        for i in reversed(range(self.timesteps)):\n",
    "            t = torch.full((batch_size,), i, device=device, dtype=torch.long)\n",
    "            x = self.p_sample(model, x, t, past_traj, era5_features)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ERA5Pooler(nn.Module):\n",
    "    \"\"\"Pool ERA5 spatial grids into fixed-size vectors.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # We'll just use spatial averaging - simple but effective!\n",
    "    \n",
    "    def forward(self, env_data_batch):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            env_data_batch: List of environmental data dicts\n",
    "        \n",
    "        Returns:\n",
    "            Tensor of shape (batch, n_timesteps, 10)\n",
    "            where 10 = 8 wind fields + 1 SST + 1 geopotential\n",
    "        \"\"\"\n",
    "        batch_features = []\n",
    "        \n",
    "        for env_timesteps in env_data_batch:  # Each sample\n",
    "            timestep_features = []\n",
    "            \n",
    "            for env in env_timesteps:  # Each of 8 timesteps\n",
    "                features = []\n",
    "                \n",
    "                # Pool wind fields (8 fields: u and v at 4 levels)\n",
    "                for level in [300, 500, 700, 850]:\n",
    "                    u = env['wind'][f'u_{level}']\n",
    "                    v = env['wind'][f'v_{level}']\n",
    "                    features.append(np.nanmean(u))\n",
    "                    features.append(np.nanmean(v))\n",
    "                \n",
    "                # Pool SST\n",
    "                features.append(np.nanmean(env['sst']))\n",
    "                \n",
    "                # Pool geopotential\n",
    "                features.append(np.nanmean(env['geopotential']))\n",
    "                \n",
    "                timestep_features.append(features)\n",
    "            \n",
    "            batch_features.append(timestep_features)\n",
    "        \n",
    "        return torch.FloatTensor(batch_features)  # (batch, 8, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Based ERA5 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNN Encoder for ERA5 Spatial Fields\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ERA5CNNEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encode ERA5 spatial grids using CNN.\n",
    "    \n",
    "    Takes multiple 2D fields and produces a fixed-size embedding vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Separate encoders for different field types (different spatial sizes)\n",
    "        \n",
    "        # Wind + SST encoder (21x21 grids)\n",
    "        # Input: 9 channels (8 wind + 1 SST)\n",
    "        self.wind_sst_encoder = nn.Sequential(\n",
    "            nn.Conv2d(9, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 21x21 -> 10x10\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 10x10 -> 5x5\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),  # 5x5 -> 1x1\n",
    "        )\n",
    "        \n",
    "        # Geopotential encoder (21x41 grids)\n",
    "        # Input: 1 channel\n",
    "        self.geo_encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 21x41 -> 10x20\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 10x20 -> 5x10\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),  # 5x10 -> 1x1\n",
    "        )\n",
    "        \n",
    "        # Combine features and project to output dimension\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(128 + 64, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, env_data_batch):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            env_data_batch: List of environmental data (batch_size samples)\n",
    "            Each sample contains 8 timesteps of ERA5 fields\n",
    "        \n",
    "        Returns:\n",
    "            Tensor of shape (batch_size, n_timesteps, output_dim)\n",
    "        \"\"\"\n",
    "        device = next(self.wind_sst_encoder.parameters()).device\n",
    "        batch_features = []\n",
    "        \n",
    "        for env_timesteps in env_data_batch:  # Each sample in batch\n",
    "            timestep_features = []\n",
    "            \n",
    "            for env in env_timesteps:  # Each of 8 timesteps\n",
    "                # Prepare wind + SST (9 channels, 21x21)\n",
    "                wind_sst_fields = []\n",
    "                for level in [300, 500, 700, 850]:\n",
    "                    wind_sst_fields.append(env['wind'][f'u_{level}'])\n",
    "                    wind_sst_fields.append(env['wind'][f'v_{level}'])\n",
    "                wind_sst_fields.append(env['sst'])\n",
    "                \n",
    "                wind_sst = np.stack(wind_sst_fields, axis=0)  # (9, 21, 21)\n",
    "                \n",
    "                # Handle NaN values (replace with mean)\n",
    "                for i in range(wind_sst.shape[0]):\n",
    "                    field = wind_sst[i]\n",
    "                    if np.any(np.isnan(field)):\n",
    "                        wind_sst[i] = np.nan_to_num(field, nan=np.nanmean(field))\n",
    "                \n",
    "                wind_sst = torch.FloatTensor(wind_sst).unsqueeze(0).to(device)  # (1, 9, 21, 21)\n",
    "                \n",
    "                # Prepare geopotential (1 channel, 21x41)\n",
    "                geo = env['geopotential']\n",
    "                if np.any(np.isnan(geo)):\n",
    "                    geo = np.nan_to_num(geo, nan=np.nanmean(geo))\n",
    "                geo = torch.FloatTensor(geo).unsqueeze(0).unsqueeze(0).to(device)  # (1, 1, 21, 41)\n",
    "                \n",
    "                # Encode\n",
    "                wind_sst_feat = self.wind_sst_encoder(wind_sst).squeeze(-1).squeeze(-1)  # (1, 128)\n",
    "                geo_feat = self.geo_encoder(geo).squeeze(-1).squeeze(-1)  # (1, 64)\n",
    "                \n",
    "                # Fuse\n",
    "                combined = torch.cat([wind_sst_feat, geo_feat], dim=1)  # (1, 192)\n",
    "                fused = self.fusion(combined)  # (1, output_dim)\n",
    "                \n",
    "                timestep_features.append(fused)\n",
    "            \n",
    "            # Stack timesteps\n",
    "            timestep_features = torch.cat(timestep_features, dim=0)  # (8, output_dim)\n",
    "            batch_features.append(timestep_features)\n",
    "        \n",
    "        return torch.stack(batch_features, dim=0)  # (batch, 8, output_dim)\n",
    "\n",
    "\n",
    "class DiffusionTransformerCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Updated Diffusion Transformer using CNN encoder for ERA5.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model=256,\n",
    "        n_heads=8,\n",
    "        n_layers=6,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # CNN encoder for ERA5\n",
    "        self.era5_encoder = ERA5CNNEncoder(output_dim=d_model)\n",
    "        \n",
    "        # Embeddings\n",
    "        self.traj_embed = nn.Linear(6, d_model)\n",
    "        self.pos_embed = nn.Linear(2, d_model)\n",
    "        \n",
    "        # Diffusion timestep embedding\n",
    "        self.time_embed = nn.Sequential(\n",
    "            SinusoidalPositionEmbedding(d_model),\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model * 4, d_model)\n",
    "        )\n",
    "        \n",
    "        # Transformer encoder for conditioning\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.condition_encoder = nn.TransformerEncoder(encoder_layer, n_layers)\n",
    "        \n",
    "        # Transformer decoder for denoising\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.denoiser = nn.TransformerDecoder(decoder_layer, n_layers)\n",
    "        \n",
    "        # Output head\n",
    "        self.output_head = nn.Linear(d_model, 2)\n",
    "        \n",
    "        # Learnable positional encoding\n",
    "        self.forecast_pos_embed = nn.Parameter(torch.randn(5, d_model))\n",
    "    \n",
    "    def forward(self, past_traj, env_data_batch, noisy_positions, diffusion_t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            past_traj: (batch, 8, 6)\n",
    "            env_data_batch: List of environmental data dicts\n",
    "            noisy_positions: (batch, 5, 2)\n",
    "            diffusion_t: (batch,)\n",
    "        \"\"\"\n",
    "        batch_size = past_traj.shape[0]\n",
    "        \n",
    "        # Encode ERA5 with CNN\n",
    "        era5_tokens = self.era5_encoder(env_data_batch)  # (batch, 8, d_model)\n",
    "        \n",
    "        # Embed trajectory\n",
    "        traj_tokens = self.traj_embed(past_traj)  # (batch, 8, d_model)\n",
    "        \n",
    "        # Concatenate conditioning\n",
    "        conditioning = torch.cat([traj_tokens, era5_tokens], dim=1)  # (batch, 16, d_model)\n",
    "        conditioning = self.condition_encoder(conditioning)\n",
    "        \n",
    "        # Embed noisy positions\n",
    "        pos_tokens = self.pos_embed(noisy_positions)  # (batch, 5, d_model)\n",
    "        pos_tokens = pos_tokens + self.forecast_pos_embed.unsqueeze(0)\n",
    "        \n",
    "        # Add diffusion timestep\n",
    "        t_embed = self.time_embed(diffusion_t)\n",
    "        pos_tokens = pos_tokens + t_embed.unsqueeze(1)\n",
    "        \n",
    "        # Denoise\n",
    "        denoised = self.denoiser(pos_tokens, conditioning)\n",
    "        predicted_noise = self.output_head(denoised)\n",
    "        \n",
    "        return predicted_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StormDatasetCNN(Dataset):\n",
    "    \"\"\"Dataset that keeps raw ERA5 grids for CNN processing.\"\"\"\n",
    "    \n",
    "    def __init__(self, pkl_file):\n",
    "        with open(pkl_file, 'rb') as f:\n",
    "            self.samples = pickle.load(f)\n",
    "        \n",
    "        # Filter valid samples\n",
    "        self.samples = [\n",
    "            s for s in self.samples \n",
    "            if all(s['targets'][f't+{fh}h'] is not None for fh in [6, 12, 24, 48, 72])\n",
    "        ]\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} valid samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Past trajectory\n",
    "        traj = torch.FloatTensor(sample['input_trajectory'])\n",
    "        \n",
    "        # ERA5 raw data (keep as-is for CNN)\n",
    "        env_data = sample['environmental_data']\n",
    "        \n",
    "        # Target positions\n",
    "        targets = []\n",
    "        for fh in [6, 12, 24, 48, 72]:\n",
    "            t = sample['targets'][f't+{fh}h']\n",
    "            targets.append([t['lat'], t['lon']])\n",
    "        targets = torch.FloatTensor(targets)\n",
    "        \n",
    "        return traj, env_data, targets\n",
    "\n",
    "\n",
    "def collate_fn_cnn(batch):\n",
    "    \"\"\"Custom collate to handle list of dicts in ERA5 data.\"\"\"\n",
    "    trajs, envs, targets = zip(*batch)\n",
    "    \n",
    "    trajs = torch.stack(trajs)\n",
    "    targets = torch.stack(targets)\n",
    "    # envs stays as list of lists of dicts\n",
    "    \n",
    "    return trajs, list(envs), targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMBINED MODEL RUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Unified Training Framework for Storm Track Forecasting\n",
    "=====================================================\n",
    "\n",
    "Three models, one data pipeline, fair comparison.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SHARED COMPONENTS\n",
    "# ============================================================================\n",
    "\n",
    "# Use the same ERA5CNNEncoder we already built\n",
    "# Use the same StormDatasetCNN we already built\n",
    "# Use the same collate_fn_cnn we already built\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 1: GRU-CNN (Baseline from Paper)\n",
    "# ============================================================================\n",
    "\n",
    "class GRUCNN_Baseline(nn.Module):\n",
    "    \"\"\"\n",
    "    GRU-CNN baseline: Direct prediction trajectory → future positions.\n",
    "    Simpler task than diffusion.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim=128, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CNN encoder for ERA5\n",
    "        self.era5_encoder = ERA5CNNEncoder(output_dim=hidden_dim)\n",
    "        \n",
    "        # Trajectory embedding\n",
    "        self.traj_embed = nn.Linear(6, hidden_dim)\n",
    "        \n",
    "        # GRU processes combined features\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=hidden_dim * 2,  # traj + era5\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Decoder: predict 5 positions directly\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim * 2, 10)  # 5 positions × 2 coords\n",
    "        )\n",
    "    \n",
    "    def forward(self, past_traj, env_data_batch):\n",
    "        \"\"\"\n",
    "        Direct prediction: past → future\n",
    "        \n",
    "        Args:\n",
    "            past_traj: (batch, 8, 6)\n",
    "            env_data_batch: list of env dicts\n",
    "        \n",
    "        Returns:\n",
    "            (batch, 5, 2) predicted positions\n",
    "        \"\"\"\n",
    "        batch_size = past_traj.shape[0]\n",
    "        \n",
    "        # Encode\n",
    "        era5_features = self.era5_encoder(env_data_batch)  # (batch, 8, hidden)\n",
    "        traj_features = self.traj_embed(past_traj)  # (batch, 8, hidden)\n",
    "        \n",
    "        # Combine\n",
    "        combined = torch.cat([traj_features, era5_features], dim=-1)  # (batch, 8, 2*hidden)\n",
    "        \n",
    "        # GRU\n",
    "        gru_out, _ = self.gru(combined)  # (batch, 8, hidden)\n",
    "        \n",
    "        # Decode from last hidden state\n",
    "        predictions = self.decoder(gru_out[:, -1, :])  # (batch, 10)\n",
    "        return predictions.view(batch_size, 5, 2)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 2: GRU-CNN with Pooled Features (Ablation)\n",
    "# ============================================================================\n",
    "\n",
    "class GRUCNN_Pooled(nn.Module):\n",
    "    \"\"\"\n",
    "    Ablation: GRU-CNN but with pooled ERA5 instead of CNN.\n",
    "    Tests if spatial structure matters.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim=128, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Simple pooling instead of CNN\n",
    "        self.era5_pooler = ERA5Pooler()\n",
    "        self.era5_embed = nn.Linear(10, hidden_dim)\n",
    "        \n",
    "        # Rest is same as CNN version\n",
    "        self.traj_embed = nn.Linear(6, hidden_dim)\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            input_size=hidden_dim * 2,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim * 2, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, past_traj, env_data_batch):\n",
    "        batch_size = past_traj.shape[0]\n",
    "        \n",
    "        # Pool ERA5 (loses spatial structure)\n",
    "        era5_pooled = self.era5_pooler(env_data_batch)  # (batch, 8, 10)\n",
    "        era5_features = self.era5_embed(era5_pooled)  # (batch, 8, hidden)\n",
    "        \n",
    "        traj_features = self.traj_embed(past_traj)\n",
    "        combined = torch.cat([traj_features, era5_features], dim=-1)\n",
    "        \n",
    "        gru_out, _ = self.gru(combined)\n",
    "        predictions = self.decoder(gru_out[:, -1, :])\n",
    "        return predictions.view(batch_size, 5, 2)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL 3: Diffusion Transformer (Your Novel Approach)\n",
    "# ============================================================================\n",
    "\n",
    "# Keep your existing DiffusionTransformerCNN and GaussianDiffusion classes\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# UNIFIED TRAINING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def train_direct_model(model, dataloader, optimizer, device, epoch, model_name):\n",
    "    \"\"\"\n",
    "    Training for GRU-CNN models (direct prediction, no diffusion).\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (traj, env_data, targets) in enumerate(dataloader):\n",
    "        traj = traj.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Direct prediction\n",
    "        predictions = model(traj, env_data)\n",
    "        \n",
    "        # MSE loss on positions\n",
    "        loss = nn.MSELoss()(predictions, targets)\n",
    "        \n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            wandb.log({\n",
    "                f'{model_name}/batch_loss': loss.item(),\n",
    "                f'{model_name}/step': epoch * len(dataloader) + batch_idx,\n",
    "            })\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_direct_model(model, dataset, device, n_samples=20):\n",
    "    \"\"\"Evaluate direct prediction models.\"\"\"\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    \n",
    "    for idx in range(min(n_samples, len(dataset))):\n",
    "        traj, env_data, actual = dataset[idx]\n",
    "        \n",
    "        pred = model(traj.unsqueeze(0).to(device), [env_data])[0].cpu().numpy()\n",
    "        actual = actual.numpy()\n",
    "        \n",
    "        # 72h error\n",
    "        lat_err = (pred[4, 0] - actual[4, 0]) * 111\n",
    "        lon_err = (pred[4, 1] - actual[4, 1]) * 111 * np.cos(np.radians(actual[4, 0]))\n",
    "        dist_err = np.sqrt(lat_err**2 + lon_err**2)\n",
    "        errors.append(dist_err)\n",
    "    \n",
    "    return np.mean(errors), np.std(errors)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# UNIFIED TRAINING SCRIPT\n",
    "# ============================================================================\n",
    "\n",
    "def train_all_models(data_path, n_epochs=100):\n",
    "    \"\"\"\n",
    "    Train all three models on the same data for fair comparison.\n",
    "    \"\"\"\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load shared dataset\n",
    "    dataset = StormDatasetCNN(data_path)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=16, \n",
    "        shuffle=True, \n",
    "        num_workers=0,\n",
    "        collate_fn=collate_fn_cnn\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # MODEL 1: GRU-CNN Baseline\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING MODEL 1: GRU-CNN Baseline\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    wandb.init(project=\"cyclone-comparison\", name=\"grucnn-baseline\", reinit=True)\n",
    "    \n",
    "    model_grucnn = GRUCNN_Baseline(hidden_dim=128, num_layers=2).to(device)\n",
    "    optimizer_grucnn = torch.optim.AdamW(model_grucnn.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "    scheduler_grucnn = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_grucnn, T_max=n_epochs)\n",
    "    \n",
    "    best_loss_grucnn = float('inf')\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
    "        \n",
    "        loss = train_direct_model(model_grucnn, dataloader, optimizer_grucnn, device, epoch, 'grucnn')\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            eval_mean, eval_std = evaluate_direct_model(model_grucnn, dataset, device)\n",
    "            wandb.log({'grucnn/eval_72h_km': eval_mean, 'grucnn/epoch': epoch})\n",
    "            print(f\"  Loss: {loss:.4f}, Eval: {eval_mean:.1f}±{eval_std:.1f} km\")\n",
    "        else:\n",
    "            print(f\"  Loss: {loss:.4f}\")\n",
    "        \n",
    "        wandb.log({'grucnn/epoch_loss': loss, 'grucnn/lr': optimizer_grucnn.param_groups[0]['lr']})\n",
    "        scheduler_grucnn.step()\n",
    "        \n",
    "        if loss < best_loss_grucnn:\n",
    "            best_loss_grucnn = loss\n",
    "            torch.save(model_grucnn.state_dict(), 'grucnn_baseline_best.pt')\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # MODEL 2: GRU-CNN Pooled (Ablation)\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING MODEL 2: GRU-CNN Pooled (Ablation)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    wandb.init(project=\"cyclone-comparison\", name=\"grucnn-pooled\", reinit=True)\n",
    "    \n",
    "    model_pooled = GRUCNN_Pooled(hidden_dim=128, num_layers=2).to(device)\n",
    "    optimizer_pooled = torch.optim.AdamW(model_pooled.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "    scheduler_pooled = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_pooled, T_max=n_epochs)\n",
    "    \n",
    "    best_loss_pooled = float('inf')\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
    "        \n",
    "        loss = train_direct_model(model_pooled, dataloader, optimizer_pooled, device, epoch, 'pooled')\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            eval_mean, eval_std = evaluate_direct_model(model_pooled, dataset, device)\n",
    "            wandb.log({'pooled/eval_72h_km': eval_mean, 'pooled/epoch': epoch})\n",
    "            print(f\"  Loss: {loss:.4f}, Eval: {eval_mean:.1f}±{eval_std:.1f} km\")\n",
    "        else:\n",
    "            print(f\"  Loss: {loss:.4f}\")\n",
    "        \n",
    "        wandb.log({'pooled/epoch_loss': loss, 'pooled/lr': optimizer_pooled.param_groups[0]['lr']})\n",
    "        scheduler_pooled.step()\n",
    "        \n",
    "        if loss < best_loss_pooled:\n",
    "            best_loss_pooled = loss\n",
    "            torch.save(model_pooled.state_dict(), 'grucnn_pooled_best.pt')\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    # ========================================================================\n",
    "    # MODEL 3: Diffusion Transformer (if you want to retry with fixes)\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SKIPPING Diffusion Transformer (can retry later if fixed)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # You can add this back once we debug the diffusion training\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"GRU-CNN Baseline best loss: {best_loss_grucnn:.4f}\")\n",
    "    print(f\"GRU-CNN Pooled best loss: {best_loss_pooled:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_models('processed_data/processed_samples_1980.pkl', n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
