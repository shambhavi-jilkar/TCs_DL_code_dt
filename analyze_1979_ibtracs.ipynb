{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Your 1979 IBTrACS Data\n",
    "\n",
    "**Goal:** Understand exactly what trajectory data you have for testing\n",
    "\n",
    "Before reading the detailed guide (`ibtracs_processing_explained.md`), let's explore your data hands-on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Final Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final processed IBTrACS file\n",
    "# This has already been cleaned through 5 processing steps\n",
    "df = pd.read_csv('IBTrACS_fore72.txt', header=None,\n",
    "                 names=['name','date','lat','lon','ws','p','speed','direct'])\n",
    "\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î What do you notice?\n",
    "\n",
    "- The first row has `66666` as name - this is the separator\n",
    "- Each cyclone starts with this separator\n",
    "- Then comes actual observations with name, time, position, intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all cyclone separators\n",
    "separator_indices = df[df['name'] == '66666'].index.tolist()\n",
    "\n",
    "print(f\"Number of cyclones in full dataset: {len(separator_indices):,}\")\n",
    "print(f\"\\nFirst 10 cyclone start indices: {separator_indices[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract ONLY 1979 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to datetime (skip separator rows)\n",
    "df_clean = df[df['name'] != '66666'].copy()\n",
    "df_clean['datetime'] = pd.to_datetime(df_clean['date'])\n",
    "df_clean['year'] = df_clean['datetime'].dt.year\n",
    "\n",
    "# Filter for 1979\n",
    "df_1979 = df_clean[df_clean['year'] == 1979].copy()\n",
    "\n",
    "print(f\"üìä 1979 DATA SUMMARY:\")\n",
    "print(f\"  Total observations: {len(df_1979):,}\")\n",
    "print(f\"  Date range: {df_1979['datetime'].min()} to {df_1979['datetime'].max()}\")\n",
    "print(f\"  Unique cyclones: {df_1979['name'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all 1979 cyclones with statistics\n",
    "print(\"\\nüåÄ 1979 TROPICAL CYCLONES:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, name in enumerate(df_1979['name'].unique(), 1):\n",
    "    storm = df_1979[df_1979['name'] == name]\n",
    "    \n",
    "    duration = (storm['datetime'].max() - storm['datetime'].min()).total_seconds() / 3600  # hours\n",
    "    n_obs = len(storm)\n",
    "    max_wind = storm['ws'].max()\n",
    "    min_pressure = storm['p'].min()\n",
    "    \n",
    "    print(f\"{i:2d}. {name:12s} | {n_obs:3d} obs | {duration:6.1f}h | \"\n",
    "          f\"Max wind: {max_wind:5.1f} kt | Min P: {min_pressure:7.1f} hPa\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ KEY INSIGHT:\n",
    "\n",
    "Count how many cyclones you found. This number determines:\n",
    "- How many training samples you can create\n",
    "- Whether 1979 alone is sufficient for testing\n",
    "- If you need data from other years too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate potential training samples\n",
    "# Each cyclone can generate multiple samples using sliding windows\n",
    "\n",
    "print(\"\\nüìà TRAINING SAMPLE POTENTIAL:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_samples = 0\n",
    "for name in df_1979['name'].unique():\n",
    "    storm = df_1979[df_1979['name'] == name]\n",
    "    n_obs = len(storm)\n",
    "    \n",
    "    # For 72-hour forecast, need:\n",
    "    # - Input: 8 observations (24 hours at 3-hr intervals)\n",
    "    # - Output: up to 24 observations (72 hours)\n",
    "    # - Minimum: 8 + 24 = 32 observations\n",
    "    \n",
    "    if n_obs >= 32:\n",
    "        # Number of sliding windows\n",
    "        samples = n_obs - 32 + 1\n",
    "        total_samples += samples\n",
    "        print(f\"{name:12s}: {n_obs:3d} obs ‚Üí {samples:3d} samples\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüéØ TOTAL POTENTIAL SAMPLES FROM 1979: {total_samples:,}\")\n",
    "print(f\"\\n‚ö†Ô∏è  Is this enough for training a diffusion model?\")\n",
    "print(f\"    Consider: Typical DiT models need 10k-100k+ samples\")\n",
    "print(f\"    Recommendation: Use 1979 for TESTING only, train on other years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize Cyclone Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all 1979 cyclone tracks\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# Add map features\n",
    "ax.add_feature(cfeature.LAND, facecolor='lightgray')\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "ax.gridlines(draw_labels=True, linewidth=0.5, alpha=0.5)\n",
    "\n",
    "# Set extent to Western Pacific\n",
    "ax.set_extent([100, 180, 0, 60], crs=ccrs.PlateCarree())\n",
    "\n",
    "# Plot each cyclone\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, df_1979['name'].nunique()))\n",
    "for i, name in enumerate(df_1979['name'].unique()):\n",
    "    storm = df_1979[df_1979['name'] == name].sort_values('datetime')\n",
    "    \n",
    "    # Plot track\n",
    "    ax.plot(storm['lon'], storm['lat'], \n",
    "            color=colors[i], linewidth=2, \n",
    "            transform=ccrs.PlateCarree(),\n",
    "            label=name)\n",
    "    \n",
    "    # Mark start and end\n",
    "    ax.plot(storm['lon'].iloc[0], storm['lat'].iloc[0], \n",
    "            'o', color=colors[i], markersize=8, \n",
    "            transform=ccrs.PlateCarree())\n",
    "    ax.plot(storm['lon'].iloc[-1], storm['lat'].iloc[-1], \n",
    "            's', color=colors[i], markersize=8, \n",
    "            transform=ccrs.PlateCarree())\n",
    "\n",
    "ax.legend(loc='upper left', fontsize=8)\n",
    "ax.set_title('1979 Western Pacific Tropical Cyclones\\n(‚óã = start, ‚ñ° = end)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('1979_cyclone_tracks.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Track map saved as '1979_cyclone_tracks.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Detailed Analysis of One Cyclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the first cyclone for detailed analysis\n",
    "first_cyclone_name = df_1979['name'].unique()[0]\n",
    "cyclone = df_1979[df_1979['name'] == first_cyclone_name].copy()\n",
    "cyclone = cyclone.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "print(f\"üîç DETAILED ANALYSIS: {first_cyclone_name}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nLifetime: {cyclone['datetime'].min()} to {cyclone['datetime'].max()}\")\n",
    "print(f\"Duration: {(cyclone['datetime'].max() - cyclone['datetime'].min()).total_seconds()/3600:.1f} hours\")\n",
    "print(f\"Number of observations: {len(cyclone)}\")\n",
    "print(f\"\\nIntensity:\")\n",
    "print(f\"  Max wind: {cyclone['ws'].max():.1f} kt\")\n",
    "print(f\"  Min pressure: {cyclone['p'].min():.1f} hPa\")\n",
    "print(f\"\\nPosition range:\")\n",
    "print(f\"  Latitude: {cyclone['lat'].min():.2f}¬∞N to {cyclone['lat'].max():.2f}¬∞N\")\n",
    "print(f\"  Longitude: {cyclone['lon'].min():.2f}¬∞E to {cyclone['lon'].max():.2f}¬∞E\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check time spacing (should be exactly 3 hours everywhere)\n",
    "time_diffs = cyclone['datetime'].diff().dt.total_seconds() / 3600\n",
    "time_diffs = time_diffs.dropna()\n",
    "\n",
    "print(f\"\\n‚è∞ TIME SPACING CHECK:\")\n",
    "print(f\"  Expected: 3.0 hours between all observations\")\n",
    "print(f\"  Actual:\")\n",
    "print(f\"    Mean: {time_diffs.mean():.2f} hours\")\n",
    "print(f\"    Min: {time_diffs.min():.2f} hours\")\n",
    "print(f\"    Max: {time_diffs.max():.2f} hours\")\n",
    "print(f\"    Std: {time_diffs.std():.2f} hours\")\n",
    "\n",
    "if time_diffs.std() < 0.01:\n",
    "    print(f\"\\n  ‚úÖ Perfect! All observations are exactly 3 hours apart\")\n",
    "else:\n",
    "    print(f\"\\n  ‚ö†Ô∏è  Warning: Some irregular time spacing detected\")\n",
    "    print(f\"  Irregular gaps: {time_diffs[time_diffs != 3.0].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize intensity evolution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Wind speed over time\n",
    "axes[0, 0].plot(cyclone['datetime'], cyclone['ws'], 'b-', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Time')\n",
    "axes[0, 0].set_ylabel('Wind Speed (kt)')\n",
    "axes[0, 0].set_title(f'{first_cyclone_name}: Wind Speed Evolution')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Pressure over time\n",
    "axes[0, 1].plot(cyclone['datetime'], cyclone['p'], 'r-', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Time')\n",
    "axes[0, 1].set_ylabel('Central Pressure (hPa)')\n",
    "axes[0, 1].set_title(f'{first_cyclone_name}: Pressure Evolution')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].invert_yaxis()  # Lower pressure = stronger storm\n",
    "\n",
    "# Plot 3: Movement speed over time\n",
    "axes[1, 0].plot(cyclone['datetime'], cyclone['speed'], 'g-', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Time')\n",
    "axes[1, 0].set_ylabel('Movement Speed (kt)')\n",
    "axes[1, 0].set_title(f'{first_cyclone_name}: Translation Speed')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Track\n",
    "axes[1, 1].plot(cyclone['lon'], cyclone['lat'], 'k-', linewidth=2)\n",
    "axes[1, 1].plot(cyclone['lon'].iloc[0], cyclone['lat'].iloc[0], \n",
    "               'go', markersize=15, label='Start')\n",
    "axes[1, 1].plot(cyclone['lon'].iloc[-1], cyclone['lat'].iloc[-1], \n",
    "               'ro', markersize=15, label='End')\n",
    "axes[1, 1].set_xlabel('Longitude (¬∞E)')\n",
    "axes[1, 1].set_ylabel('Latitude (¬∞N)')\n",
    "axes[1, 1].set_title(f'{first_cyclone_name}: Track')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{first_cyclone_name}_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Analysis plot saved as '{first_cyclone_name}_analysis.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create One Sample (What the Model Will See)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single training sample\n",
    "# Input: Past 24 hours (8 observations at 3-hr intervals)\n",
    "# Output: Future positions for 6, 12, 24, 48, 72 hours\n",
    "\n",
    "# Take observations 10-17 as input (indices 10-17)\n",
    "input_start = 10\n",
    "input_end = input_start + 8\n",
    "\n",
    "input_data = cyclone.iloc[input_start:input_end].copy()\n",
    "current_time = input_data['datetime'].iloc[-1]\n",
    "current_pos = (input_data['lat'].iloc[-1], input_data['lon'].iloc[-1])\n",
    "\n",
    "print(f\"\\nüì¶ SAMPLE CREATION EXAMPLE:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nCurrent time (t=0): {current_time}\")\n",
    "print(f\"Current position: ({current_pos[0]:.2f}¬∞N, {current_pos[1]:.2f}¬∞E)\")\n",
    "\n",
    "print(f\"\\nüì• INPUT (Past 24 hours):\")\n",
    "for i, row in input_data.iterrows():\n",
    "    hours_ago = (current_time - row['datetime']).total_seconds() / 3600\n",
    "    print(f\"  t-{hours_ago:4.0f}h: ({row['lat']:6.2f}¬∞N, {row['lon']:7.2f}¬∞E) | \"\n",
    "          f\"WS: {row['ws']:5.1f} kt | P: {row['p']:7.1f} hPa\")\n",
    "\n",
    "# Find future positions\n",
    "forecast_hours = [6, 12, 24, 48, 72]\n",
    "print(f\"\\nüì§ TARGET (Future positions):\")\n",
    "for fh in forecast_hours:\n",
    "    target_time = current_time + timedelta(hours=fh)\n",
    "    # Find the observation closest to target time\n",
    "    time_diff = abs(cyclone['datetime'] - target_time)\n",
    "    closest_idx = time_diff.idxmin()\n",
    "    \n",
    "    if time_diff[closest_idx].total_seconds() / 3600 <= 1.5:  # Within 1.5 hours\n",
    "        target_row = cyclone.loc[closest_idx]\n",
    "        print(f\"  t+{fh:3d}h: ({target_row['lat']:6.2f}¬∞N, {target_row['lon']:7.2f}¬∞E)\")\n",
    "    else:\n",
    "        print(f\"  t+{fh:3d}h: NO DATA (cyclone ended or data gap)\")\n",
    "\n",
    "print(\"\\nüí° This is ONE training sample!\")\n",
    "print(\"   With sliding windows, you can create many more from each cyclone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "### What You've Learned:\n",
    "\n",
    "1. ‚úÖ How many cyclones are in your 1979 data\n",
    "2. ‚úÖ The data structure and format\n",
    "3. ‚úÖ How to verify data quality (3-hour spacing, no gaps)\n",
    "4. ‚úÖ How sliding windows create multiple samples\n",
    "5. ‚úÖ What input/output pairs look like for the model\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "- **Number of 1979 cyclones:** (printed above)\n",
    "- **Total potential samples:** (printed above)\n",
    "- **Data quality:** Time spacing verified\n",
    "\n",
    "### What's Missing:\n",
    "\n",
    "This is JUST the trajectory data. To train the model, you also need:\n",
    "\n",
    "1. **ERA5 environmental data** for each timestamp:\n",
    "   - Wind fields (u,v) at 300, 500, 700, 850 hPa\n",
    "   - Sea surface temperature (SST)\n",
    "   - Geopotential height\n",
    "\n",
    "2. **Devortexing** of wind fields (removing cyclone's own circulation)\n",
    "\n",
    "3. **Feature engineering** (19 trajectory features mentioned in paper)\n",
    "\n",
    "4. **Normalization** of all variables\n",
    "\n",
    "### Next Actions:\n",
    "\n",
    "**Option 1: Connect to ERA5** (Recommended first)\n",
    "- Use the `era5_data_exploration_1979.ipynb` notebook\n",
    "- Extract environmental data for one cyclone timestamp\n",
    "- Verify alignment between IBTrACS and ERA5\n",
    "\n",
    "**Option 2: Understand Devortexing**\n",
    "- Study the `meteor_factor.ipynb` code\n",
    "- Run devortexing on one wind field sample\n",
    "- Visualize before/after comparison\n",
    "\n",
    "**Option 3: Full Pipeline**\n",
    "- Process all 1979 cyclones end-to-end\n",
    "- Create complete training samples\n",
    "- Save in format ready for your Diffusion Transformer\n",
    "\n",
    "**Which one should you tackle first?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
